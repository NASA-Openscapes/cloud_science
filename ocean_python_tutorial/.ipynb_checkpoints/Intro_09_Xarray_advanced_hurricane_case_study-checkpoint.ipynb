{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [SC57 - Working with big, multi-dimensional geoscientific datasets in Python: a tutorial introduction to xarray](http://meetingorganizer.copernicus.org/EGU2017/session/25651)  \n",
    "  \n",
    "  \n",
    "* Original notebook by [Stephan Hoyer](http://stephanhoyer.com), Rossbypalooza, 2016.  \n",
    "* Modified by Edward Byers, Matthew Gidden and [Fabien Maussion](http://fabienmaussion.info/) for EGU General Assembly 2017, Vienna, Austria\n",
    "* Modified by C. Gentemann for GHRSST Science Team Tutorial 2019, Rome, Italy\n",
    "* Modified by C. Gentemann for OceanHackWeek 2019, Seattle, WA\n",
    "* PODAACPY file search added by Lewis John McGibbney\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure of this tutorial\n",
    "\n",
    "1. Searching for data at NASA's PODAAC\n",
    "1. Opening data\n",
    "1. Data plotting, exploration, subsetting\n",
    "1. Comparing two datasets\n",
    "1. Comparing timeseries of data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Key features of `xarray`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  `xarray` is an open source project and Python package\n",
    "*  `xarray` has been designed to perform **labelled** data analysis on **multi-dimensional** arrays\n",
    "* the `xarray` approach adopts the Common Data Model for **self-describing scientific data** in widespread use in the Earth sciences\n",
    "*  `xarray.Dataset` is an in-memory representation of a netCDF file.\n",
    "* `xarray` is built on top of the dataprocessing library [Pandas](http://pandas.pydata.org) (the best way to work with tabular data (e.g., CSV files) in Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our data\n",
    "\n",
    "- numeric\n",
    "- multi-dimensional\n",
    "- labelled\n",
    "- (lots of) metadata\n",
    "- sometimes (very) large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is `xarray` good for?\n",
    "* Gridded, multi-dimensional and large datasets, commonly used in earth sciences, but also increasingly finance, engineering (signal/image processing), and biological sciences\n",
    "* Integration with other data analysis packages such as Pandas \n",
    "* I/O operations (NetCDF)\n",
    "* Plotting\n",
    "* Out of core computation and parallel processing\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Basic operations in `xarray`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "## Import python packages\n",
    "\n",
    "You are going to want numpy, pandas, matplotlib.pyplot, podaaacpy, and xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore') # filter some warning messages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "\n",
    "from pathlib import Path\n",
    "import configparser\n",
    "from lxml import objectify\n",
    "\n",
    "#for search capabilites import podaacpy\n",
    "import podaac.podaac as podaac\n",
    "from podaac import drive as podaacdrive\n",
    "import podaac.podaac_utils as putil\n",
    "# then create an instance of the Podaac class\n",
    "p = podaac.Podaac()\n",
    "with open('./podaac.ini', 'r') as f:\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read_file(f)\n",
    "    d = podaacdrive.Drive(None, \n",
    "                          config['drive']['urs_username'], \n",
    "                          config['drive']['urs_password'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of SSTs during Hurricane Irene\n",
    "\n",
    "Irene was a massive storm, with tropical storm force winds extending outward 300 miles (485 km). The storm was also slow moving as it traversed the Mid-Atlantic. Irene claimed at least 48 lives and caused over 7 billion U.S. dollars in damages in the U.S. and 3.1 billion U.S. dollars of damage in the Caribbean. (source: https://www.ncdc.noaa.gov/sotc/tropical-cyclones/201113).\n",
    "\n",
    "For this tutorial we will use the podaacpy to search for SST2 during Hurricane Irene and look at the change in upper ocean heat content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num files: 10\n",
      "num files: 10\n"
     ]
    }
   ],
   "source": [
    "dataset_id_mur = 'PODAAC-GHCMC-4FM02'\n",
    "#dataset_id_mur = 'PODAAC-GHCMC-4FM03'  #CMC SST looked up on podaac website\n",
    "#dataset_id_mur = 'PODAAC-GHGMR-4FJ04'  #MUR SST looked up on podaac website\n",
    "#dataset_id_mur = 'PODAAC-GHGDM-4FD02'  #DMI\n",
    "dataset_id_ostia = 'PODAAC-GHOST-4FK01' #ostia sst\n",
    "\n",
    "start_time = '2011-08-24T00:00:00Z'\n",
    "end_time = '2011-09-01T23:59:59Z'\n",
    "gresult = p.granule_search(dataset_id=dataset_id_mur,\n",
    "                           start_time=start_time,\n",
    "                           end_time=end_time,\n",
    "                           items_per_page='100')\n",
    "urls = putil.PodaacUtils.mine_opendap_urls_from_granule_search(gresult)\n",
    "urls_mur = [w[:-5] for w in urls]  #remove html from urlsurls_sst = [w.replace('-tools.jpl.nasa.gov/drive/files/', '-opendap.jpl.nasa.gov/opendap/') for w in urls_sst]\n",
    "print('num files:',len(urls_mur))\n",
    "gresult = p.granule_search(dataset_id=dataset_id_ostia,\n",
    "                           start_time=start_time,\n",
    "                           end_time=end_time,\n",
    "                           items_per_page='100')\n",
    "urls = putil.PodaacUtils.mine_opendap_urls_from_granule_search(gresult)\n",
    "urls_ostia = [w[:-5] for w in urls]  #remove html from urlsurls_sst = [w.replace('-tools.jpl.nasa.gov/drive/files/', '-opendap.jpl.nasa.gov/opendap/') for w in urls_sst]\n",
    "print('num files:',len(urls_ostia))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with the MUR SST dataset. Other tutorial examples [here](https://github.com/pydata/xarray/tree/master/examples).\n",
    "\n",
    "## 2. Examining your data\n",
    "\n",
    "* With well designed mdatasets that follow Climate Forecast (CF) conventions, you will usually get coordinates of lat,lon,time which makes it easy to select data and visualize it in different ways.  \n",
    "\n",
    "* Notice that the time is automatically converted into a np.datetime64 format which can be queried for month, day, etc.  All the variables that are CF compliant are automatically converted (if needed) and read in so that you can immediately start working with the data.  \n",
    "\n",
    "* Above, you can see that the dimensions are lat, lon, and time\n",
    "\n",
    "* The coordinates of the datasets are also lat,lon, and time\n",
    "\n",
    "\n",
    "use [xr.open_dataset](http://xarray.pydata.org/en/stable/generated/xarray.open_dataset.html) to open the provided url and print the dataset\n",
    "\n",
    "* url is a text string to an online dataset.  When you open a file, you can just use the file name and path or you can just use the url for files that are available online.  If you are running this on the cloud you could even call cloud located data\n",
    "\n",
    "* Here, we are reading in a global SST dataset called CMC from NASA's PO.DAAC\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open a SST dataset using the filename retrieved by podaacpy\n",
    "Below, let's open MUR SSTs using xarray and a PODAAC OpenDAP URL.\n",
    "To open a file use [xr.open_dataset](http://xarray.pydata.org/en/stable/generated/xarray.open_dataset.html)\n",
    "\n",
    "The url filename we want to use is already included for you.  You can give a local filename or an opendap URL.\n",
    "\n",
    "Then just print out the file details by just typing the dataset name, ds_sst_mur\n",
    "\n",
    "## Metadata --- Examining your data\n",
    "\n",
    "\n",
    "* The data variable (analysed_sst) has the labeled dimensions and metadata attached.  You can see additional metadata (if it exists) by looking at the data variable of interest.  \n",
    "\n",
    "* Below, type \n",
    "```ds_sst_mur.ana``` then hit tab to autocomplete.  \n",
    "* Then run the cell by holding shift and pressing enter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open & Subset the data using .sel to the North Atlantic region using slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening: https://podaac-opendap.jpl.nasa.gov/opendap/allData/ghrsst/data/GDS2/L4/GLOB/CMC/CMC0.2deg/v2/2011/235/20110823120000-CMC-L4_GHRSST-SSTfnd-CMC0.2deg-GLOB-v02.0-fv02.0.nc <xarray.Dataset>\n",
      "Dimensions:           (lat: 151, lon: 301, time: 1)\n",
      "Coordinates:\n",
      "  * time              (time) datetime64[ns] 2011-08-23T12:00:00\n",
      "  * lat               (lat) float32 15.0 15.2 15.4 15.6 ... 44.4 44.6 44.8 45.0\n",
      "  * lon               (lon) float32 -100.0 -99.8 -99.6 ... -40.4 -40.2 -40.0\n",
      "Data variables:\n",
      "    analysed_sst      (time, lat, lon) float32 ...\n",
      "    analysis_error    (time, lat, lon) float32 ...\n",
      "    sea_ice_fraction  (time, lat, lon) float32 ...\n",
      "    mask              (time, lat, lon) float32 ...\n",
      "Attributes:\n",
      "    Conventions:                CF-1.4\n",
      "    title:                      CMC 0.2 deg global sea surface temperature an...\n",
      "    summary:                    Applies the method of statistical interpolati...\n",
      "    references:                 Brasnett B. 2008. The impact of satellite ret...\n",
      "    institution:                CMC\n",
      "    history:                    Processed through sfc.thin_sst, sfc.sstobs, i...\n",
      "    comment:                    WARNING Some applications are unable to prope...\n",
      "    license:                    GHRSST protocol describes data use as free an...\n",
      "    id:                         CMC0.2deg-CMC-L4-GLOB-v2.0\n",
      "    naming_authority:           org.ghrsst\n",
      "    product_version:            2.0\n",
      "    uuid:                       67270ff2-25d7-4390-8bc1-fee0a6209243\n",
      "    gds_version_id:             02.5\n",
      "    netcdf_version_id:          4.3.0\n",
      "    date_created:               20131004T160340Z\n",
      "    file_quality_level:         3\n",
      "    spatial_resolution:         0.2 degree\n",
      "    start_time:                 20110823T000000Z\n",
      "    time_coverage_start:        20110823T000000Z\n",
      "    stop_time:                  20110824T000000Z\n",
      "    time_coverage_end:          20110824T000000Z\n",
      "    northernmost_latitude:      90.0\n",
      "    southernmost_latitude:      -90.0\n",
      "    westernmost_longitude:      -180.0\n",
      "    easternmost_longitude:      179.8\n",
      "    source:                     EUR-L2P-ATS_NR_2P,REMSS_GRIDDED_25-AMSRE,NAVO...\n",
      "    platform:                   Envisat,Aqua,NOAA-18,Coriolis,MetOpA,NOAA-19\n",
      "    sensor:                     AATSR,AMSRE,AVHRR_GAC,Windsat\n",
      "    metadata_link:              http://podaac.jpl.nasa.gov/ws/metadata/datase...\n",
      "    Metadata_Conventions:       Unidata Observation Dataset v1.0\n",
      "    keywords:                   Oceans > Ocean Temperature > Sea Surface Temp...\n",
      "    keywords_vocabulary:        NASA Global Change Master Directory (GCMD) Sc...\n",
      "    standard_name_vocabulary:   NetCDF Climate and Forecast (CF) Metadata Con...\n",
      "    geospatial_lat_units:       degrees_north\n",
      "    geospatial_lat_resolution:  0.2\n",
      "    geospatial_lon_units:       degrees_east\n",
      "    geospatial_lon_resolution:  0.2\n",
      "    acknowledgment:             Please acknowledge the use of these data with...\n",
      "    creator_name:               Bruce Brasnett, Environment Canada\n",
      "    creator_email:              Bruce.Brasnett@ec.gc.ca\n",
      "    creator_url:                http://www.ec.gc.ca/scitech/default.asp?lang=...\n",
      "    project:                    Group for High Resolution Sea Surface Tempera...\n",
      "    publisher_name:             GHRSST Project Office\n",
      "    publisher_url:              http://www.ghrsst.org\n",
      "    publisher_email:            ghrsst-po@nceo.ac.uk\n",
      "    processing_level:           L4\n",
      "    cdm_data_type:              grid\n"
     ]
    }
   ],
   "source": [
    "ds_sst = xr.open_dataset(urls_mur[0])\n",
    "subset_sst = ds_sst.sel(lat=slice(15,45),lon=slice(-100,-40))\n",
    "print('opening:', urls_mur[0],subset_sst)\n",
    "#subset_sst.analysed_sst.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the SST.  \n",
    "### Notice xarray adds labels and title to the plot and colorbar.  \n",
    "\n",
    "Sometimes the metadata is great and you get exactly the label you need, but sometimes you want to change the label.  Xarray plotting [help](http://xarray.pydata.org/en/stable/plotting.html). A really nice feature of xarray is that it uses the metadata to label the axis.  Let's change the colorbar label by changing the `long_name` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_sst.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the attributes for `analysed_sst`\n",
    "print(subset_sst.analysed_sst.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the attributes for `analysed_sst`\n",
    "subset_sst.analysed_sst.attrs['units']='K'\n",
    "subset_sst.analysed_sst.attrs['long_name']='SST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2,figsize=[12,4])\n",
    "\n",
    "subset_sst.analysed_sst.plot(ax=axes[0])\n",
    "\n",
    "subset_sst.mask.plot(ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask out land values using .where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_sst_masked = subset_sst.where(subset_sst.mask==1)\n",
    "subset_sst_masked.analysed_sst.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare time series of the cold wake after Hurricane as measured by MUR and OSTIA SSTs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When you open a multi-file dataset, xarray uses dask for lasy loading.  \n",
    "* Lazy loading: It mostly just loads the metadata. You can do data searching, selecting, subsetting without acutally loading the data. \n",
    "* Here we have loaded in 30 days of data for two very high resolution SST global datasets.  Before we actually load the data, we are going to want to do some subsetting so that it will fit into our memory.\n",
    "* Notice below when you print out the dataset details that they are all stored as dask.array types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sst = xr.open_mfdataset(urls_mur,coords='minimal')\n",
    "ds_sstlo = xr.open_mfdataset(urls_ostia,coords='minimal')\n",
    "ds_sstlo['time'] = ds_sstlo.indexes['time'].to_datetimeindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset data\n",
    "subset_sst = ds_sst.sel(lat=slice(15,45),lon=slice(-100,-40))\n",
    "subset_sstlo = ds_sstlo.sel(lat=slice(15,45),lon=slice(-100,-40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_sst.load()\n",
    "subset_sstlo.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subset_sst_interp_time = subset_sst.interp(time=subset_sstlo.time,\n",
    "                                      method='linear')\n",
    "subset_sst_interp = subset_sst_interp_time.interp(lat=subset_sstlo.lat,\n",
    "                                      lon=subset_sstlo.lon,\n",
    "                                      method='nearest')\n",
    "# now use the sst mask on the wnd data\n",
    "subset_sstlo_masked = subset_sstlo.where(subset_sst_interp.mask==1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2,figsize=[12,4])\n",
    "\n",
    "(subset_sst.analysed_sst[-1,:,:]-subset_sst.analysed_sst[0,:,:]).plot(vmin=-1,vmax=1,ax=axes[0])\n",
    "\n",
    "\n",
    "(subset_sstlo_masked.analysed_sst[-1,:,:]-subset_sstlo_masked.analysed_sst[0,:,:]).plot(vmin=-1,vmax=1,ax=axes[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where can I find more info?\n",
    "\n",
    "### For more information about xarray\n",
    "\n",
    "- Read the [online documentation](http://xarray.pydata.org/)\n",
    "- Ask questions on [StackOverflow](http://stackoverflow.com/questions/tagged/python-xarray)\n",
    "- View the source code and file bug reports on [GitHub](http://github.com/pydata/xarray/)\n",
    "\n",
    "### For more doing data analysis with Python:\n",
    "\n",
    "- Thomas Wiecki, [A modern guide to getting started with Data Science and Python](http://twiecki.github.io/blog/2014/11/18/python-for-data-science/)\n",
    "- Wes McKinney, [Python for Data Analysis](http://shop.oreilly.com/product/0636920023784.do) (book)\n",
    "\n",
    "### Packages building on xarray for the geophysical sciences\n",
    "\n",
    "For analyzing GCM output:\n",
    "\n",
    "- [xgcm](https://github.com/xgcm/xgcm) by Ryan Abernathey\n",
    "- [oogcm](https://github.com/lesommer/oocgcm) by Julien Le Sommer\n",
    "- [MPAS xarray](https://github.com/pwolfram/mpas_xarray) by Phil Wolfram\n",
    "- [marc_analysis](https://github.com/darothen/marc_analysis) by Daniel Rothenberg\n",
    "\n",
    "Other tools:\n",
    "\n",
    "- [windspharm](https://github.com/ajdawson/windspharm): wind spherical harmonics by Andrew Dawson\n",
    "- [eofs](https://github.com/ajdawson/eofs): empirical orthogonal functions by Andrew Dawson\n",
    "- [infinite-diff](https://github.com/spencerahill/infinite-diff) by Spencer Hill \n",
    "- [aospy](https://github.com/spencerahill/aospy) by Spencer Hill and Spencer Clark\n",
    "- [regionmask](https://github.com/mathause/regionmask) by Mathias Hauser\n",
    "- [salem](https://github.com/fmaussion/salem) by Fabien Maussion\n",
    "\n",
    "Resources for teaching and learning xarray in geosciences:\n",
    "- [Fabien's teaching repo](https://github.com/fmaussion/teaching): courses that combine teaching climatology and xarray\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

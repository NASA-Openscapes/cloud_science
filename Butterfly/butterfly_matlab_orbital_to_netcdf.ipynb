{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take shannon matlab & put into netcdf\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import h5py\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "#PLOTTING\n",
    "import cartopy\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.colorbar import Colorbar\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "#resampling to grid\n",
    "from pyresample.geometry import AreaDefinition\n",
    "from pyresample.geometry import GridDefinition\n",
    "from pyresample import image, geometry, load_area, save_quicklook, SwathDefinition, area_def2basemap\n",
    "from pyresample.kd_tree import resample_nearest\n",
    "from pyresample.utils import check_and_wrap\n",
    "from scipy import spatial\n",
    "\n",
    "import glob\n",
    "\n",
    "#where to find the data\n",
    "adir_data= 'f:/data/project_data/fluxsat/orbit/'\n",
    "adir_figs= 'f:/data/project_data/fluxsat/figures/'\n",
    "\n",
    "# add land mask\n",
    "#get bathymetry from ETOPO1\n",
    "fname_topo = 'F:/data/topo/ETOPO1_Ice_g_gmt4.grd'\n",
    "ds = xr.open_dataset(fname_topo)\n",
    "ds_topo = ds.rename_dims({'x':'lon','y':'lat'}).rename({'x':'lon','y':'lat'})\n",
    "tem = ds_topo.attrs\n",
    "ds_topo = ds_topo.rename({'z':'etopo_depth'})\n",
    "ds_topo.etopo_depth.attrs=tem\n",
    "_, index = np.unique(ds_topo['lon'], return_index=True)\n",
    "ds_topo = ds_topo.isel(lon=index)\n",
    "_, index = np.unique(ds_topo['lat'], return_index=True)\n",
    "ds_topo = ds_topo.isel(lat=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all filenames\n",
    "filenames = glob.glob(adir_data+'FS*.mat')\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data from all 3 files, put into xarray dataset\n",
    "#change UTCtime from days since 0000/1/1 to datetime64 object\n",
    "#make utctime the coordinate\n",
    "ds_sv=[]\n",
    "for fname in filenames:\n",
    "    f = h5py.File(fname,mode='r') #open file \n",
    "    struArray = f['rad']\n",
    "    ilen =  struArray['SClat']['data'].shape[0]\n",
    "    da = xr.DataArray(None, coords=[np.arange(ilen)], dims=['iob'])\n",
    "    ds = xr.Dataset({'test':xr.DataArray(None, coords=[np.arange(ilen)], dims=['iob'])})\n",
    "    for v in struArray:\n",
    "        data = struArray[v]['data']\n",
    "        da = xr.DataArray(data[:,0], coords=[np.arange(ilen)], dims=['iob'])\n",
    "        ds[v]=da\n",
    "    ds['UTCtime'] = np.datetime64('0000-01-01')+ds.UTCtime.astype('timedelta64[D]')+((ds.UTCtime-ds.UTCtime[0])*24*60*60*1e9).astype('timedelta64[ns]')\n",
    "    ds = ds.drop('test')\n",
    "    ds = ds.swap_dims({'iob':'UTCtime'}).reset_coords()\n",
    "    ds_sv.append(ds)\n",
    "ds = xr.concat(ds_sv, dim='UTCtime')\n",
    "#ds['UTCtime']=np.datetime64('0000-01-01')+ds.UTCtime.astype('int').data.astype('timedelta64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 1 day of data dataarray in xarray\n",
    "dylist = ['2018-11-28','2018-11-29','2018-11-30']\n",
    "da_sv = []\n",
    "for dnum,dstr in enumerate(dylist):\n",
    "    dy = ds.sel(UTCtime=slice(dylist[dnum],dylist[dnum]))\n",
    "    for iorbit in range(16):\n",
    "        i1=iorbit*2777296\n",
    "        i2=(iorbit+1)*2777296\n",
    "        i2= [dy.blon.size-1 if i2>dy.blon.size else i2]\n",
    "        i2=i2[0]\n",
    "        dy2 = dy.sel(UTCtime=slice(dy.UTCtime[i1],dy.UTCtime[i2]))       \n",
    "        x = dy2.blon.data\n",
    "        y = dy2.blat.data\n",
    "        z = dy2.blat.data*0+1\n",
    "        lons,lats,data = x,y,z \n",
    "        lons,lats = check_and_wrap(lons, lats)\n",
    "        swath_def = SwathDefinition(lons, lats)\n",
    "        grid_def_lons, grid_def_lats = np.arange(-180,180,0.1), np.arange(-90,90,0.1)\n",
    "        grid_mesh_lons,grid_mesh_lats = np.meshgrid(grid_def_lons,grid_def_lats)\n",
    "        grid_def = GridDefinition(lons=grid_mesh_lons,lats=grid_mesh_lats)\n",
    "        result1 = resample_nearest(swath_def, data, grid_def, radius_of_influence=20000, fill_value=None)\n",
    "        rr=np.expand_dims(result1,axis=2)\n",
    "        iorbit_num = iorbit+dnum*16\n",
    "        da = xr.DataArray(rr,name='sec',\n",
    "                          coords={'lat':grid_def_lats,'lon':grid_def_lons,'orbit':[iorbit_num]},\n",
    "                          dims=('lat','lon','orbit'))\n",
    "        da_sv.append(da)\n",
    "da2 = xr.concat(da_sv, dim='orbit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = ds.drop({'SCinc','iob','SCalt','belev','bhorz','binc','scanang','SClat','SClon'})\n",
    "fname_out = adir_data + '3dys_butterfly_obs.nc'\n",
    "ds.to_netcdf(fname_out)\n",
    "fname_out = adir_data + '3dys_butterfly_grid.nc'\n",
    "da2.to_netcdf(fname_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#breakup\n",
    "fname_out = adir_data + '3dys_butterfly_grid.nc'\n",
    "ds = xr.open_dataset(fname_out)\n",
    "fname_out = adir_data + '3dys_butterfly_gridA.nc'\n",
    "ds.sec[:,:,0:16].to_netcdf(fname_out,encoding={\"sec\": {\"dtype\": \"int8\", \"scale_factor\": 0.1, \"zlib\": True, \"complevel\": 9}})\n",
    "fname_out = adir_data + '3dys_butterfly_gridB.nc'\n",
    "ds.sec[:,:,16:32].to_netcdf(fname_out,encoding={\"sec\": {\"dtype\": \"int8\", \"scale_factor\": 0.1, \"zlib\": True, \"complevel\": 9}})\n",
    "fname_out = adir_data + '3dys_butterfly_gridC.nc'\n",
    "ds.sec[:,:,32:].to_netcdf(fname_out,encoding={\"sec\": {\"dtype\": \"int8\", \"scale_factor\": 0.1, \"zlib\": True, \"complevel\": 9}})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem = xr.open_dataset(fname_out)\n",
    "tem.close()\n",
    "tem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem.sec[:,:,0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAC data\n",
    "from scipy.io import loadmat\n",
    "#load data\n",
    "x = loadmat(adir_data + 'clayson_fluxes.mat')\n",
    "#put into xarray dataarray\n",
    "da_lo = xr.DataArray(x['lhf1deg'], \n",
    "                     coords={'latlo':x['lat1deg'][0],'lonlo':x['lon1deg'][0]}, \n",
    "                     dims=['lonlo','latlo']).T\n",
    "da_hi = xr.DataArray(x['lhfhires'], \n",
    "                     coords={'lat':x['latitude'][:,0],'lon':x['longitude'][:,0]}, \n",
    "                     dims=['lon','lat']).T\n",
    "#put into xarray dataset & write to netcdf file\n",
    "ds = xr.Dataset({'lo':da_lo,'hi':da_hi})\n",
    "ds.to_netcdf(adir_data + 'clayson_fluxes.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_hi.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shannons different resolution fluxes\n",
    "#fname = adir_data + 'shannon_flux_res.mat'\n",
    "# CAC data\n",
    "from scipy.io import loadmat\n",
    "#load data\n",
    "x = loadmat(adir_data + 'shannon_flux_res.mat')\n",
    "lat1 = x['XI'][1,:]\n",
    "lon1 = x['YI'][:,1]\n",
    "hi = x['hires']\n",
    "lo = x['lores']\n",
    "#put into xarray dataarray\n",
    "da_lo = xr.DataArray(lo, \n",
    "                     coords={'lat':lat1,'lon':lon1,'res':[0,1,2,3]}, \n",
    "                     dims=['lon','lat','res']).T\n",
    "da_hi = xr.DataArray(hi, \n",
    "                     coords={'lat':lat1,'lon':lon1,'res':[0,1,2]}, \n",
    "                     dims=['lon','lat','res']).T\n",
    "#put into xarray dataset & write to netcdf file\n",
    "ds = xr.Dataset({'lo':da_lo,'hi':da_hi})\n",
    "ds.to_netcdf(adir_data + 'clayson_fluxes_hilo.nc')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.hi[0,:,:].sel(lon=slice(120,180),lat=slice(10,50)).plot(cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.hi[2,:,:].sel(lon=slice(120,180),lat=slice(10,50)).plot(cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pangeo ERA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notebook based on zflemings:https://nbviewer.jupyter.org/github/zflamig/dask-era5/blob/main/notebook/era5_fargate_dask.ipynb\n",
    "import xarray as xr\n",
    "import fsspec\n",
    "import dask\n",
    "import s3fs\n",
    "import numpy as np\n",
    "xr.set_options(display_style=\"html\")  #display dataset nicely "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "import fsspec\n",
    "import xarray as xr\n",
    "\n",
    "with xr.open_zarr(fsspec.get_mapper('gcs://pangeo-era5/reanalysis/spatial-analysis'),\n",
    "                  consolidated=True,\n",
    "                  chunks='auto') as ds:\n",
    "    print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from intake import open_catalog\n",
    "cat = open_catalog(\"https://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/atmosphere.yaml\")\n",
    "ds  = cat[\"era5_hourly_reanalysis_single_levels_sa\"].to_dask()\n",
    "ds_wnd = ds.u10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_wnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_wnd[0,:,:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = ds_wnd.sel(longitude=slice(236,239),latitude=slice(46,41)).mean({'latitude','longitude'}).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.to_netcdf('../../data/era5ts.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=ts.sel(time=slice('2017','2020'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS ERA5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if zac's data more recent?\n",
    "#https://nbviewer.jupyter.org/github/awslabs/amazon-asdi/blob/main/examples/dask/notebooks/era5_zarr.ipynb\n",
    "\n",
    "%matplotlib inline\n",
    "import boto3\n",
    "import botocore\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import s3fs\n",
    "import fsspec\n",
    "import dask\n",
    "from dask.distributed import performance_report, Client, progress\n",
    "\n",
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 18}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zac code\n",
    "def fix_accum_var_dims(ds, var):\n",
    "    # Some varibles like precip have extra time bounds varibles, we drop them here to allow merging with other variables\n",
    "    \n",
    "    # Select variable of interest (drops dims that are not linked to current variable)\n",
    "    ds = ds[[var]]  \n",
    "\n",
    "    if var in ['air_temperature_at_2_metres',\n",
    "               'dew_point_temperature_at_2_metres',\n",
    "               'air_pressure_at_mean_sea_level',\n",
    "               'northward_wind_at_10_metres',\n",
    "               'eastward_wind_at_10_metres']:\n",
    "        \n",
    "        ds = ds.rename({'time0':'valid_time_end_utc'})\n",
    "        \n",
    "    elif var in ['precipitation_amount_1hour_Accumulation',\n",
    "                 'integral_wrt_time_of_surface_direct_downwelling_shortwave_flux_in_air_1hour_Accumulation']:\n",
    "        \n",
    "        ds = ds.rename({'time1':'valid_time_end_utc'})\n",
    "        \n",
    "    else:\n",
    "        print(\"Warning, Haven't seen {var} varible yet! Time renaming might not work.\".format(var=var))\n",
    "        \n",
    "    return ds\n",
    "\n",
    "@dask.delayed\n",
    "def s3open(path):\n",
    "    fs = s3fs.S3FileSystem(anon=True, default_fill_cache=False, \n",
    "                           config_kwargs = {'max_pool_connections': 20})\n",
    "    return s3fs.S3Map(path, s3=fs)\n",
    "\n",
    "\n",
    "def open_era5_range(start_year, end_year, variables):\n",
    "    ''' Opens ERA5 monthly Zarr files in S3, given a start and end year (all months loaded) and a list of variables'''\n",
    "    \n",
    "    \n",
    "    file_pattern = 'era5-pds/zarr/{year}/{month}/data/{var}.zarr/'\n",
    "    \n",
    "    years = list(np.arange(start_year, end_year+1, 1))\n",
    "    months = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]\n",
    "    \n",
    "    l = []\n",
    "    for var in variables:\n",
    "        print(var)\n",
    "        \n",
    "        # Get files\n",
    "        files_mapper = [s3open(file_pattern.format(year=year, month=month, var=var)) for year in years for month in months]\n",
    "        \n",
    "        # Look up correct time dimension by variable name\n",
    "        if var in ['precipitation_amount_1hour_Accumulation']:\n",
    "            concat_dim='time1'\n",
    "        else:\n",
    "            concat_dim='time0'\n",
    "            \n",
    "        # Lazy load\n",
    "        ds = xr.open_mfdataset(files_mapper, engine='zarr', \n",
    "                               concat_dim=concat_dim, combine='nested', \n",
    "                               coords='minimal', compat='override', parallel=True)\n",
    "        \n",
    "        # Fix dimension names\n",
    "        ds = fix_accum_var_dims(ds, var)\n",
    "        l.append(ds)\n",
    "        \n",
    "    ds_out = xr.merge(l)\n",
    "    \n",
    "    return ds_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ds = open_era5_range(1979, 2020, [\"eastward_wind_at_10_metres\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.eastward_wind_at_10_metres.sel(lon=slice(235,245),lat=slice(45,35),valid_time_end_utc='2017-10-08T18').plot(vmin=-3,vmax=5,cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = ds.sel(lon=slice(236,239),lat=slice(46,41)).mean({'lat','lon'}).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "for lyr in range(1979,2021):\n",
    "    yr = ts.sel(valid_time_end_utc=slice(str(lyr)+'-08-01',str(lyr)+'-10-29'))\n",
    "    xx=yr.valid_time_end_utc.dt.dayofyear+yr.valid_time_end_utc.dt.hour/24\n",
    "    ax.plot(xx,yr.eastward_wind_at_10_metres,color='silver')\n",
    "color_order = ['green','grey','blue','red']\n",
    "for i,lyr in enumerate(np.arange(2017,2021)):\n",
    "    yr = ts.sel(valid_time_end_utc=slice(str(lyr)+'-08-01',str(lyr)+'-10-29'))\n",
    "    ax.plot(xx,yr.eastward_wind_at_10_metres,color=color_order[i])\n",
    "date_form = DateFormatter(\"%m-%d\")\n",
    "ax.xaxis.set_major_formatter(date_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_sr = ds.sel(lon=slice(237,240),lat=slice(42,40)).mean({'lat','lon'}).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "for lyr in range(1979,2021):\n",
    "    yr = ts_sr.sel(valid_time_end_utc=slice(str(lyr)+'-08-01',str(lyr)+'-10-29'))\n",
    "    xx=yr.valid_time_end_utc.dt.dayofyear+yr.valid_time_end_utc.dt.hour/24\n",
    "    ax.plot(xx,yr.eastward_wind_at_10_metres,color='silver')\n",
    "color_order = ['green','grey','blue','red']\n",
    "for i,lyr in enumerate(np.arange(2017,2021)):\n",
    "    yr = ts_sr.sel(valid_time_end_utc=slice(str(lyr)+'-08-01',str(lyr)+'-10-29'))\n",
    "    ax.plot(xx,yr.eastward_wind_at_10_metres,color=color_order[i])\n",
    "date_form = DateFormatter(\"%m-%d\")\n",
    "ax.xaxis.set_major_formatter(date_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.to_netcdf('../../data/era5ts.nc')\n",
    "ts_sr.to_netcdf('../../data/era5ts_sr.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

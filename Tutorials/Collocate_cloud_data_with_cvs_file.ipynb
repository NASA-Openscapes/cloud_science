{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on collocating a dataset  with lagged data\n",
    "\n",
    "#1) You will need to point the code to your input file.\n",
    "\n",
    "#2) Ensure that your input file has the following Variables and Names:\n",
    "    #Latitude = 'lat'\n",
    "    #Longitude = 'lon'\n",
    "    #Time = 'time'\n",
    "    #Year = 'year'\n",
    "    #Month = 'month'\n",
    "    #Day = 'day'\n",
    "    #Date = 'date'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import timeit\n",
    "import glob\n",
    "# filter some warning messages\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "#from geopy.distance import geodesic \n",
    "\n",
    "####################you will need to change some paths here!#####################\n",
    "#list of input files\n",
    "#filename_bird='f:/data/project_data/NASA_biophysical/collocated_data/zoo_selgroups_HadSST_relabundance_5aug2019_plumchrusV_4regions_final.csv'\n",
    "\n",
    "#adir = 'F:/data/project_data/NASA_biophysical/jeff_collocations/'\n",
    "adir = './../../data/'\n",
    "\n",
    "filename_bird=adir + 'allStationMetadata.csv'\n",
    "\n",
    "#output files\n",
    "filename_bird_out= adir + 'zoo_selgroups_HadSST_relabundance_5aug2019_plumchrusV_4regions_final_satsst'\n",
    "#################################################################################\n",
    "\n",
    "#import intake\n",
    "import dask\n",
    "import dask.array as dsa\n",
    "import gcsfs\n",
    "import fsspec\n",
    "\n",
    "#subroutines to read data\n",
    "#some of the data is on pangeo gcp, some on AWS\n",
    "import sys\n",
    "sys.path.append('./../subroutines/')  #where your\n",
    "from get_data_pangeo import get_data,get_sst\n",
    "#from get_data_local import get_sst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading CSV datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in csv file in to panda dataframe & into xarray\n",
    "df_bird = pd.read_csv(filename_bird)\n",
    "df_bird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate time, it needs a datetime64[ns] format\n",
    "df_bird.insert(0,'Year',df_bird['year'])\n",
    "df_bird.insert(1,'Month',df_bird['month'])\n",
    "df_bird.insert(2,'Day',df_bird['day'])\n",
    "df_bird=df_bird.drop(columns={'day','month','year'})\n",
    "df_bird['time'] = df_bird['time'].apply(lambda x: x.zfill(8))\n",
    "df_bird.insert(3,'Hour',df_bird['time'].apply(lambda x: x[:2]))\n",
    "df_bird.insert(4,'Min',df_bird['time'].apply(lambda x: x[3:5]))\n",
    "df_bird.insert(0,'time64',pd.to_datetime(df_bird[list(df_bird)[0:4]]))\n",
    "df_bird=df_bird.drop(columns={'Day','Month','Year','Hour','Min','time','date'})\n",
    "\n",
    "# transform to x array\n",
    "ds_bird = df_bird.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just check lat/lon & see looks okay\n",
    "minlat,maxlat=ds_bird.lat.min(),ds_bird.lat.max()\n",
    "minlon,maxlon=ds_bird.lon.min(),ds_bird.lon.max()\n",
    "plt.scatter(ds_bird.lon,ds_bird.lat)\n",
    "print(minlat,maxlat,minlon,maxlon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from dask_gateway import Gateway\n",
    "#from dask.distributed import Client\n",
    "#gateway = Gateway()\n",
    "#cluster = gateway.new_cluster()\n",
    "#cluster.adapt(minimum=1, maximum=200)\n",
    "#cluster.scale(50)\n",
    "#client = Client(cluster)\n",
    "#cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resolution of the Satellite Data is 0.2 degrees.\n",
    "#If you want to smooth the data, change smooth_lat and smooth lon to the number of \n",
    "#grid cells you want to include.  \n",
    "#example: smooth_lat = 3 will compute a rolling average over 3 grid cells which equals 0.6 deg \n",
    "#smooth_lat=1\n",
    "#smooth_lon=1\n",
    "#ds = ds.rolling(lat=smooth_lat,center=True,keep_attrs=True).mean(keep_attrs=True)\n",
    "#ds = ds.rolling(lon=smooth_lon,center=True,keep_attrs=True).mean(keep_attrs=True)\n",
    "#ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collocate all data with bird data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilen_bird = len(ds_bird.lat)\n",
    "ilen_bird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get MUR SST\n",
    "#file_location = 's3://mur-sst/zarr'\n",
    "#ds = xr.open_zarr(fsspec.get_mapper(file_location, anon=True),consolidated=True)\n",
    "#ds_sst = ds.drop({'analysis_error','mask','sea_ice_fraction'})\n",
    "#tem = ds_sst.analysed_sst.attrs\n",
    "#tem['var_name']='mur_sst'\n",
    "#ds_sst.analysed_sst.attrs=tem\n",
    "#data={'sst':ds_sst}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just include last 30 days of data\n",
    "data,clim = get_data()\n",
    "for name in data:\n",
    "    ds_data=data[name]\n",
    "    print('data',name)\n",
    "    if name=='aviso':\n",
    "        continue\n",
    "    if name=='wnd':\n",
    "        continue\n",
    "    if name=='color':\n",
    "        continue\n",
    "    if name=='topo':\n",
    "        continue\n",
    "    if name=='topo':\n",
    "        temlat,temlon = ds_bird.lat,ds_bird.lon\n",
    "        tem2=ds_data.z.interp(lat=temlat,lon=temlon,method='nearest') \n",
    "        ds['ETOPO_depth']=xr.DataArray(tem2.data, coords={'index': ds_bird.index}, dims=('index'))\n",
    "        ds['ETOPO_depth'].attrs = ds_data.attrs\n",
    "    else:\n",
    "        for var in ds_data:\n",
    "            var_tem=var\n",
    "            ds_bird[var_tem]=xr.DataArray(np.empty((ilen_bird,31), dtype=str(ds_data[var].dtype)), coords={'index': ds_bird.index,'dtime':np.arange(-30,1)}, dims=('index','dtime'))\n",
    "            ds_bird[var_tem].attrs=ds_data[var].attrs\n",
    "        for i in range(len(ds_bird.lat)):\n",
    "            t1,t2 = ds_bird.time64[i]-np.timedelta64(30,'D')+np.timedelta64(9,'h'), ds_bird.time64[i]+np.timedelta64(9,'h')\n",
    "            lat1,lat2=ds_bird.lat[i]-.25,ds_bird.lat[i]+.25\n",
    "            lon1,lon2=ds_bird.lon[i]-.25,ds_bird.lon[i]+.25\n",
    "            if name=='color':   #lat pos to neg\n",
    "                lat2,lat1=ds_bird.lat[i]-.25,ds_bird.lat[i]+.25\n",
    "            tem = ds_data.sel(time=slice(t1,t2),lat=slice(lat1,lat2),lon=slice(lon1,lon2)).load()\n",
    "            tem = tem.interp(lat=ds_bird.lat[i],lon=ds_bird.lon[i])\n",
    "            for var in ds_data:\n",
    "                var_tem=var\n",
    "                ds_bird[var_tem][i,:]=tem[var].data\n",
    "            if int(i/1)*1==i:\n",
    "                print(i,len(ds_bird.lat))\n",
    "    #output data\n",
    "    ds_bird.to_netcdf(filename_bird_out+name+'.nc')\n",
    "    print('output:',filename_bird_out+name+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put it all together and create a csv file\n",
    "filename = glob.glob('./../data/'+filename_bird_out+'*.nc')\n",
    "fnames\n",
    "\n",
    "print(filename[0])\n",
    "ds = xr.open_dataset(filename[0])\n",
    "for iname in range(1,len(filename)):\n",
    "    print(filename[iname])\n",
    "    ds2 = xr.open_dataset(filename[iname])\n",
    "    for var in ds2:\n",
    "        if not var in ds:\n",
    "            ds[var]=ds2[var]\n",
    "                \n",
    "ds.to_netcdf(filename_bird_out+'all'+'.nc')\n",
    "df_bird = ds.to_dataframe()\n",
    "df_bird.to_csv(filename_bird_out+'all'+'.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code below here doesn't run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rolling means at set days\n",
    "#this has errors that I don't understand\n",
    "#run without dask cluster it just dies quietly with no errors\n",
    "#run with a dask cluster it dies with get_item errors and kills cluster\n",
    "#also rolling keep_attrs doesn't seem to preserve attributes so I had to write subroutine\n",
    "data,clim = get_data()\n",
    "for name in data:\n",
    "    ds_data=data[name]\n",
    "    ds_mon = ds_data.rolling(time=30, center=False).mean(dim='time',keep_attrs=True)\n",
    "    ds_mon = set_attr(ds_data,ds_mon)\n",
    "    ilat,ilon = len(ds_mon.lat.data),len(ds_mon.lon.data)\n",
    "    ds_15 = ds_data.rolling(time=15, center=False).mean(dim='time',keep_attrs=True)\n",
    "    ds_15 = set_attr(ds_data,ds_15)\n",
    "    ds_week = ds_data.rolling(time=7, center=False).mean(dim='time',keep_attrs=True)\n",
    "    ds_week = set_attr(ds_data,ds_week)\n",
    "    ds_2dy = ds_data.rolling(time=2, center=False).mean(dim='time',keep_attrs=True)\n",
    "    ds_2dy = set_attr(ds_data,ds_2dy)\n",
    "    for var in ds_data:\n",
    "        ds_data[var+'_1mon']=ds_mon[var]\n",
    "        ds_data[var+'_15dy']=ds_15[var]\n",
    "        ds_data[var+'_1week']=ds_week[var]\n",
    "        ds_data[var+'_2dy']=ds_2dy[var]  \n",
    "    if name=='topo':\n",
    "        continue\n",
    "    for var in ds_data:\n",
    "        var_tem=var\n",
    "        ds_bird[var_tem]=xr.DataArray(np.empty(ilen_bird, dtype=str(ds_data[var].dtype)), coords={'index': ds_bird.index}, dims=('index'))\n",
    "        ds_bird[var_tem].attrs=ds_data[var].attrs\n",
    "    print('var',var_tem)\n",
    "    for i in range(len(ds_bird.lat)):\n",
    "        #tem = ds_data.sel(time=ds_bird.time64[i])\n",
    "        #tem = ds_data.sel(time=slice(t1,t2),lat=slice(lat1,lat2),lon=slice(lon1,lon2)).load()\n",
    "        ilat,ilon = len(ds_data.lat.data),len(ds_data.lon.data)\n",
    "        tem = ds_data.sel(time=ds_bird.time64[i],method='nearest')\n",
    "        tem = tem.chunk(chunks={'lat':ilat,'lon':ilon})\n",
    "        tem = tem.interp(lat=ds_bird.lat[i],lon=ds_bird.lon[i])\n",
    "        tem = tem.load()\n",
    "        for var in ds_data:\n",
    "            var_tem=var\n",
    "            ds_bird[var_tem][i]=tem[var].data\n",
    "        if int(i/10)*10==i:\n",
    "            print(i,len(ds_bird.lat))\n",
    "\n",
    "    #output data\n",
    "   #df_bird = ds_bird.to_dataframe()\n",
    "    #df_bird.to_csv(filename_bird_out)\n",
    "    ds_bird.to_netcdf(filename_bird_out+name+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test rolling to check\n",
    "print(da.data)\n",
    "da = xr.DataArray(np.linspace(0, 11, num=12),coords=[pd.date_range( \"15/12/1999\", periods=12, freq=pd.DateOffset(months=1), )],dims=\"time\",)\n",
    "dar = da.rolling(time=3,center=False).mean()  #before and up too\n",
    "print(dar.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access CCMP data on Pangeo\n",
    "\n",
    "## [More info](https://podaac.jpl.nasa.gov/MEaSUREs-CCMP?sections=about)\n",
    "\n",
    "The Cross-Calibrated Multi-Platform (CCMP) Ocean Surface Wind Vector Analyses is part of the NASA Making Earth System Data Records for Use in Research Environments (MEaSUREs) Program. MEaSUREs, develops consistent global- and continental-scale Earth System Data Records by supporting projects that produce data using proven algorithms and input.\n",
    "\n",
    "CCMP (Atlas et al., 2011) provides a consistent, gap-free long-term time-series of ocean surface wind vector analysis fields from July 1987 through June 2011. The CCMP datasets combine cross-calibrated satellite winds using a Variational Analysis Method (VAM) to produce a high-resolution (0.25 degree) gridded analysis.\n",
    "\n",
    "Reference: Atlas, R., R. N. Hoffman, J. Ardizzone, S. M. Leidner, J. C. Jusem, D. K. Smith, D. Gombos, 2011: A cross-calibrated, multiplatform ocean surface wind velocity product for meteorological and oceanographic applications. Bull. Amer. Meteor. Soc., 92, 157-174. doi: 10.1175/2010BAMS2946.1\n",
    "\n",
    "Data is NRT from 4/1/2019 - present.\n",
    "\n",
    "## Credit:\n",
    "- [Chelle Gentemann](mailto:cgentemann@faralloninstitute.org), [Farallon Institute](http://www.faralloninstitute.org/), [Twitter](https://twitter.com/ChelleGentemann) - creation of Zarr data store and tutorial\n",
    "- [Charles Blackmon Luca](mailto:blackmon@ldeo.columbia.edu), [LDEO](https://www.ldeo.columbia.edu/) - help with moving to Pangeo storage and intake update\n",
    "- [Willi Rath](mailto:wrath@geomar.de), [GEOMAR](https://www.geomar.de/en/), [Twitter](https://twitter.com/RathWilli) - motivated CG to move data to Pangeo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libs for reading data\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import intake\n",
    "import dask\n",
    "\n",
    "#libs for dask gateway\n",
    "from dask_gateway import Gateway\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a cluster, a group of computers that will work together.\n",
    "\n",
    "(A cluster is the key to big data analysis on on Cloud.)\n",
    "\n",
    "- This will set up a [dask kubernetes](https://docs.dask.org/en/latest/setup/kubernetes.html) cluster for your analysis and give you a path that you can paste into the top of the Dask dashboard to visualize parts of your cluster.  \n",
    "- You don't need to paste the link below into the Dask dashboard for this to work, but it will help you visualize progress.\n",
    "- Try 20 workers to start (during the tutorial) but you can increase to speed things up later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gateway = Gateway()\n",
    "cluster = gateway.new_cluster()\n",
    "cluster.adapt(minimum=1, maximum=80)\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ☝️ Don’t forget to click the link above or copy it to the Dask dashboard ![images.png](attachment:images.png) on the left to view the scheduler dashboard! **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Dataset\n",
    "\n",
    "Here we load the dataset from the zarr store. Note that this very large dataset (273 GB) initializes nearly instantly, and we can see the full list of variables and coordinates.\n",
    "\n",
    "### Examine Metadata\n",
    "\n",
    "For those unfamiliar with this dataset, the variable metadata is very helpful for understanding what the variables actually represent\n",
    "Printing the dataset will show you the dimensions, coordinates, and data variables with clickable icons at the end that show more metadata and size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cat_pangeo = intake.open_catalog(\"https://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/master.yaml\")\n",
    "\n",
    "ds_ccmp = cat_pangeo.atmosphere.nasa_ccmp_wind_vectors.to_dask()\n",
    "\n",
    "ds_ccmp['wspd'] = np.sqrt(ds_ccmp.uwnd**2 + ds_ccmp.vwnd**2)\n",
    "\n",
    "ds_ccmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot a timeseries of the average wind speed over a region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ds_ccmp.sel(latitude=slice(30,50),longitude=slice(200,210)).mean({'latitude','longitude'}).wspd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot a map of the annual average wind speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ds_ccmp.sel(time=slice('2000-01-01','2000-12-31')).mean({'time'}).wspd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a Hovmoller type plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ds_ccmp.sel(latitude=0.125,longitude=slice(120,275)).wspd.plot(vmin=3,vmax=15,cmap='seismic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make timeseries of global wind speed trends\n",
    "- create climatology\n",
    "- remove annual cycle\n",
    "- calculate anomaly\n",
    "- calculate trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccmp_climatology = ds_ccmp.groupby('time.dayofyear').mean('time',keep_attrs=True,skipna=False)\n",
    "ccmp_anomaly = ds_ccmp.groupby('time.dayofyear')-ccmp_climatology\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccmp_anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccmp_anomaly.wspd[:,350,720].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "#linear regression to PSD\n",
    "XX = ccmp_anomaly.time.data\n",
    "YY = \n",
    "reg = LinearRegression().fit(XX.reshape(-1, 1), YY)\n",
    "a = float(reg.coef_)\n",
    "b = -1*float(reg.intercept_)\n",
    "plt.loglog(f[istart:iend], f[istart:iend]**(a)/np.exp(b),'r') #test from fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a first-degree polyfit\n",
    "regressions = np.polyfit(np.arange(48208), ccmp_anomaly.wspd, 1)\n",
    "# Get the coefficients back\n",
    "trends = regressions[0,:].reshape(vals.shape[1], vals.shape[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccmp_anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to buoy data\n",
    "Data from NDBC buoys, which measure wind speed are [here](https://dods.ndbc.noaa.gov/) and can be read via an THREDDS server.\n",
    "- read in NDBC buoy data\n",
    "- find closest CCMP data and linearly interpolate to buoy location\n",
    "- examine a timeseries, caluclate bias and STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://dods.ndbc.noaa.gov/thredds/dodsC/data/cwind/51000/51000.ncml'\n",
    "ds = xr.open_dataset(url)\n",
    "# The longitude is on a -180 to 180, CCMP is 0-360, so make sure to convert\n",
    "ds.coords['longitude'] = np.mod(ds['longitude'], 360)\n",
    "ds_buoy = ds\n",
    "ds_buoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccmp_buoy = ds_ccmp.interp(latitude=ds_buoy.latitute,longitude=ds_buoy.longitude,method='linear')\n",
    "data_bias = (ds_buoy.wind_spd - ccmp_buoy.wspd).mean()\n",
    "data_std = (ds_buoy.wind_spd - ccmp_buoy.wspd).mean()\n",
    "print(data_bias,data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_buoy.wind_spd.plot(color='b')\n",
    "ccmp_buoy.wspd.plot(color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ds_buoy.wind_spd - ccmp_buoy.wspd,c=ds_buoy.wind_spd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

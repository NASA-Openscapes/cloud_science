{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCMP Winds in a cloud-optimized-format for Pangeo\n",
    "\n",
    "The Cross-Calibrated Multi-Platform (CCMP) Ocean Surface Wind Vector Analyses is part of the NASA Making Earth System Data Records for Use in Research Environments (MEaSUREs) Program. MEaSUREs, develops consistent global- and continental-scale Earth System Data Records by supporting projects that produce data using proven algorithms and input.  If you use this data, please give [credit](https://podaac.jpl.nasa.gov/MEaSUREs-CCMP?sections=about).  For more information, please review the [documentation](https://podaac-tools.jpl.nasa.gov/drive/files/allData/ccmp/L2.5/docs/ccmp_users_guide.pdf).\n",
    "\n",
    "# Accessing cloud satellite data\n",
    "\n",
    "- CCMP zarr conversion funding: Interagency Implementation and Advanced Concepts Team [IMPACT](https://earthdata.nasa.gov/esds/impact) for the Earth Science Data Systems (ESDS) program and AWS Public Dataset Program\n",
    "  \n",
    "### Credits: Tutorial development\n",
    "* [Dr. Chelle Gentemann](mailto:gentemann@faralloninstitute.org) -  [Twitter](https://twitter.com/ChelleGentemann)   - Farallon Institute\n",
    "\n",
    "### Zarr data format\n",
    "\n",
    " [Zarr](https://zarr.readthedocs.io/en/stable/)\n",
    "\n",
    "### Data proximate computing\n",
    "These are BIG datasets that you can analyze on the cloud without downloading the data. You can run this on your phone, a Raspberry Pi, laptop, or desktop.   \n",
    "By using public cloud data, your science is reproducible and easily shared!\n",
    "\n",
    "### To run this notebook\n",
    "\n",
    "Code is in the cells that have <span style=\"color: blue;\">In [  ]:</span> to the left of the cell and have a colored background\n",
    "\n",
    "To run the code:\n",
    "- option 1) click anywhere in the cell, then hold `shift` down and press `Enter`\n",
    "- option 2) click on the Run button at the top of the page in the dashboard\n",
    "\n",
    "Remember:\n",
    "- to insert a new cell below press `Esc` then `b`\n",
    "- to delete a cell press `Esc` then `dd`\n",
    "\n",
    "### First start by importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libs for reading data\n",
    "import xarray as xr\n",
    "import gcsfs\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from xhistogram.xarray import histogram\n",
    "\n",
    "#lib for dask gateway\n",
    "from dask_gateway import Gateway\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a cluster, a group of computers that will work together.\n",
    "\n",
    "(A cluster is the key to big data analysis on on Cloud.)\n",
    "\n",
    "- This will set up a [dask kubernetes](https://docs.dask.org/en/latest/setup/kubernetes.html) cluster for your analysis and give you a path that you can paste into the top of the Dask dashboard to visualize parts of your cluster.  \n",
    "- You don't need to paste the link below into the Dask dashboard for this to work, but it will help you visualize progress.\n",
    "- Try 20 workers to start (during the tutorial) but you can increase to speed things up later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gateway = Gateway()\n",
    "cluster = gateway.new_cluster()\n",
    "cluster.adapt(minimum=1, maximum=75)\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ☝️ Don’t forget to click the link above or copy it to the Dask dashboard ![images.png](attachment:images.png) on the left to view the scheduler dashboard! **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Dataset\n",
    "\n",
    "Here we load the dataset from the zarr store. Note that this very large dataset (273 GB) initializes nearly instantly, and we can see the full list of variables and coordinates.\n",
    "\n",
    "### Examine Metadata\n",
    "\n",
    "For those unfamiliar with this dataset, the variable metadata is very helpful for understanding what the variables actually represent\n",
    "Printing the dataset will show you the dimensions, coordinates, and data variables with clickable icons at the end that show more metadata and size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zstore = 'gs://pangeo-nasa-ccmp/zarr'\n",
    "\n",
    "fs = gcsfs.GCSFileSystem(project='pangeo-181919',requester_pays=True)\n",
    "\n",
    "ds = xr.open_zarr(fs.get_mapper(zstore))\n",
    "\n",
    "ds['wspd']=np.sqrt(ds.uwnd**2+ds.vwnd**2)\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot a global image of the data on 7/28/2020\n",
    "\n",
    "``xarray`` makes plotting the data very easy.  A nice overview of plotting with xarray is [here](http://xarray.pydata.org/en/stable/plotting.html).  Details on [.plot](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.plot.html#xarray.DataArray.plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = ds.sel(time='2020-07-04T00')\n",
    "\n",
    "day.nobs.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a land/ocean/ice mask to show where there is actually data\n",
    "\n",
    "### Two different ways to mask the data\n",
    "1. A daily mask that removes data with sea ice and land\n",
    "- sum over time for nobs (number of observations) variable\n",
    "- average over a month so that land and monthly sea ice are masked out\n",
    "2. A mask that removes all data that over land or where there is 'permanent' sea ice\n",
    "- find when nobs is > 0\n",
    "3. A climatology mask that removes all data that over land or where there has ever been sea ice\n",
    "- sum over time for nobs (number of observations) variable\n",
    "- average over a month so that land and monthly sea ice are masked out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply the mask \n",
    "- only show data (over the ocean) where there are satellite observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#daily mask removes sea ice and land\n",
    "mask_obs = ds.rolling(time=180,center=True).max('time')  #4 per day 30 days = 180 rolling window\n",
    "dy_mask = mask_obs.nobs>0\n",
    "masked1 = ds.wspd.where(dy_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# land mask only (includes data over sea ice)\n",
    "total_nobs = ds.nobs.sum({'time'},keep_attrs=True)  #this will give you a LAND mask\n",
    "land_mask = total_nobs>0\n",
    "masked2 = ds.wspd.where(land_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#climatology mask removes max sea ice extent and land\n",
    "all_nobs = mask_obs.nobs.sum({'time'},keep_attrs=True)\n",
    "clim_mask = all_nobs>125000\n",
    "masked3 = ds.wspd.where(clim_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize=(18,6))\n",
    "masked1.isel(time=1000).plot(ax=ax[0])\n",
    "masked2.isel(time=1000).plot(ax=ax[1])\n",
    "masked3.isel(time=1000).plot(ax=ax[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide which mask to use 1=land/ice, 2=land, 3=climatology\n",
    "masked = masked3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from http://gallery.pangeo.io/repos/pangeo-gallery/cmip6/global_mean_surface_temp.html\n",
    "def global_mean(ds):\n",
    "    lat = ds.latitude\n",
    "    weight = np.cos(np.deg2rad(lat))\n",
    "    weight /= weight.mean()\n",
    "    other_dims = set(ds.dims) - {'time'}\n",
    "    return (ds * weight).mean(other_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glb_mn = global_mean(subset)\n",
    "glb_mn = glb_mn.compute()\n",
    "print(glb_mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I wish I didn't have to have these loops.  Programatically, it would be much cleaner to just say subset.mean() but it kills my kernel (memory?) every time I try\n",
    "# originally I did year by year, but even that was getting ~400GB & killing the kernel\n",
    "# so now trying month by month.\n",
    "m,x=[],[]\n",
    "for lyr in range(1988,2020):\n",
    "    mm,xx=[],[]\n",
    "    for imon in range(1,13):\n",
    "        t1 = np.datetime64(str(lyr)+'-'+str(imon).zfill(2))\n",
    "        t2 = t1 + np.timedelta64(1,'M')\n",
    "        subset = masked.sel(time=slice(t1,t2)).isel(time=slice(0,-1))\n",
    "        m1 = global_mean(subset)\n",
    "        m1 = m1.mean()\n",
    "        m1_computed = m1.compute()\n",
    "        mm.append(m1_computed)\n",
    "        month_length = subset.time.dt.days_in_month[0]\n",
    "        xx.append(int(month_length))\n",
    "    mm_mn = xr.concat(mm, dim='time')\n",
    "    m.append(sum(mm_mn*xx)/sum(xx))\n",
    "    x.append(lyr)\n",
    "mn_month = xr.concat(m, dim='time')\n",
    "glb_mn = np.mean(mn_month)\n",
    "print(glb_mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0,30,.1)\n",
    "h,x=[],[]\n",
    "for lyr in range(1988,2020):\n",
    "    subset = masked.sel(time=slice(str(lyr),str(lyr)))\n",
    "    h1 = histogram(subset, bins=[bins])\n",
    "    h1 = h1.compute()\n",
    "    print('start',lyr)\n",
    "    h.append(h1)\n",
    "    x.append(lyr)\n",
    "    hh = xr.concat(h, dim='time')\n",
    "    hh.to_netcdf('./../../data/ccmp/ccmp_annual_hist.nc')\n",
    "    print('end',lyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hhall = hh.sum('time')\n",
    "hhall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr = hh[0,:].load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('percentage of winds =< 2 m/s',hhall[0:21].sum()/hhall.sum())\n",
    "print('percentage of winds =< 6 m/s',hhall[0:60].sum()/hhall.sum())\n",
    "print('percentage of winds > 6 m/s',hhall[60:].sum()/hhall.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (8,8)\n",
    "for iyr in range(27):\n",
    "    plt.plot(hh.wspd_bin,hh2.histogram_wspd[iyr,:]/hh2.histogram_wspd[iyr,:].sum(),label=str(x[iyr]))\n",
    "plt.legend(fontsize=8)\n",
    "plt.xlim(-0,32)\n",
    "plt.ylim(0,.013)\n",
    "plt.xlabel('CCMP Wind Speed (m s$^{-1}$)',fontsize=18)\n",
    "plt.ylabel('PDF (s m$^{-1}$)',fontsize=18)\n",
    "plt.text(10,0.011,'CCMPv2 1988-2020 ',fontsize=18)\n",
    "plt.text(10,0.010,'Global mean = 8.3 m s$^{-1}$',fontsize=16)\n",
    "plt.text(10,0.009,'67% of winds are > 6 m s$^{-1}$',fontsize=16)\n",
    "plt.savefig('./../../figures/ccmp_annual_hist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (8,8)\n",
    "hhall = hh2.sum('time')\n",
    "plt.plot(hh.wspd_bin,hhall.histogram_wspd/hhall.histogram_wspd.sum(),linewidth=5)\n",
    "plt.xlim(-0,30)\n",
    "plt.ylim(0,.012)\n",
    "plt.xlabel('CCMP Wind Speed (m s$^{-1}$)',fontsize=18)\n",
    "plt.ylabel('PDF (s m$^{-1}$)',fontsize=18)\n",
    "plt.text(10,0.011,'CCMPv2 1988-2020 ',fontsize=18)\n",
    "plt.text(10,0.010,'Global mean = 8.3 m s$^{-1}$',fontsize=18)\n",
    "plt.text(10,0.009,'67% of winds are > 6 m s$^{-1}$',fontsize=18)\n",
    "plt.savefig('./../../figures/ccmp_all_hist2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g6 = hhall.sel(wspd_bin=slice(6.0,35)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l6 = hhall.sel(wspd_bin=slice(0,6)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0,30,.1)\n",
    "m,x=[],[]\n",
    "for lyr in range(1988,2020):\n",
    "    subset = masked.sel(time=slice(str(lyr),str(lyr)))\n",
    "    m1 = subset.wspd.mean().load()\n",
    "    m.append(m1)\n",
    "mm = xr.concat(m, dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('global mean wind speed', mm.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xx,mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

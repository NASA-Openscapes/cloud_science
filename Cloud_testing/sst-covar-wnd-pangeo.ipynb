{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy import signal\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.stats.stats import pearsonr\n",
    "import intake\n",
    "#libs for reading data\n",
    "import xarray as xr\n",
    "import gcsfs\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import fsspec\n",
    "import s3fs\n",
    "\n",
    "#lib for dask gateway\n",
    "from dask_gateway import Gateway\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gateway = Gateway()\n",
    "cluster = gateway.new_cluster()\n",
    "cluster.adapt(minimum=1, maximum=20)\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cat_pangeo = intake.open_catalog(\"https://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/master.yaml\")\n",
    "list(cat_pangeo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "zstore = 'gs://pangeo-nasa-ccmp/zarr'\n",
    "\n",
    "fs = gcsfs.GCSFileSystem(project='pangeo-181919',requester_pays=True)\n",
    "\n",
    "ds = xr.open_zarr(fs.get_mapper(zstore), consolidated=True)\n",
    "\n",
    "ds['wspd'] = np.sqrt(ds.uwnd**2 + ds.vwnd**2)\n",
    "\n",
    "ds_ccmp = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "file_location = 's3://mur-sst/zarr-v1'\n",
    "\n",
    "ikey = fsspec.get_mapper(file_location, anon=True)\n",
    "\n",
    "ds_sst = xr.open_zarr(ikey,consolidated=True)\n",
    "\n",
    "ds_sst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample data and create climatologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_sst.analysed_sst[0,:1799,:3600].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_sst.mask[0,:1799,:3600].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sst_masked = ds_sst.where(ds_sst.mask==1)\n",
    "sst_masked.analysed_sst[0,2500:3500,:3600].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_25km = sst_masked.interp({'lon':ds_ccmp.longitude,'lat':ds_ccmp.latitude})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyr1,cyr2='2010-01-01','2019-12-31'\n",
    "#make day average\n",
    "ds_ccmp = ds_ccmp.resample(time='D').mean()\n",
    "ds_ccmp_clim = ds_ccmp.sel(time=slice(cyr1,cyr2))\n",
    "ds_ccmp_clim = ds_ccmp_clim.groupby('time.dayofyear').mean('time',keep_attrs=True,skipna=False)\n",
    "\n",
    "#sst 25km\n",
    "ds_sst_clim = sst_masked.sel(time=slice(cyr1,cyr2))\n",
    "ds_sst_clim = ds_sst_clim.groupby('time.dayofyear').mean('time',keep_attrs=True,skipna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    #put data into a dictionary\n",
    "    data_dict={'wnd':ds_ccmp,\n",
    "               'sst':ds_sst}\n",
    "    clim_dict={'wnd_clim':ds_ccmp_clim,\n",
    "               'sst_clim':ds_sst_clim}\n",
    "  \n",
    "    return data_dict,clim_dict\n",
    "\n",
    "\n",
    "def multi_apply_along_axis(func1d, axis, arrs, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    function from: https://climate-cms.org/2019/07/29/multi-apply-along-axis.html\n",
    "    Given a function `func1d(A, B, C, ..., *args, **kwargs)`  that acts on \n",
    "    multiple one dimensional arrays, apply that function to the N-dimensional\n",
    "    arrays listed by `arrs` along axis `axis`\n",
    "    \n",
    "    If `arrs` are one dimensional this is equivalent to::\n",
    "    \n",
    "        func1d(*arrs, *args, **kwargs)\n",
    "    \n",
    "    If there is only one array in `arrs` this is equivalent to::\n",
    "    \n",
    "        numpy.apply_along_axis(func1d, axis, arrs[0], *args, **kwargs)\n",
    "        \n",
    "    All arrays in `arrs` must have compatible dimensions to be able to run\n",
    "    `numpy.concatenate(arrs, axis)`\n",
    "    \n",
    "    Arguments:\n",
    "        func1d:   Function that operates on `len(arrs)` 1 dimensional arrays,\n",
    "                  with signature `f(*arrs, *args, **kwargs)`\n",
    "        axis:     Axis of all `arrs` to apply the function along\n",
    "        arrs:     Iterable of numpy arrays\n",
    "        *args:    Passed to func1d after array arguments\n",
    "        **kwargs: Passed to func1d as keyword arguments\n",
    "    \"\"\"\n",
    "    import numpy\n",
    "    # Concatenate the input arrays along the calculation axis to make one big\n",
    "    # array that can be passed in to `apply_along_axis`\n",
    "    carrs = numpy.concatenate(arrs, axis)\n",
    "    \n",
    "    # We'll need to split the concatenated arrays up before we apply `func1d`,\n",
    "    # here's the offsets to split them back into the originals\n",
    "    offsets=[]\n",
    "    start=0\n",
    "    for i in range(len(arrs)-1):\n",
    "        start += arrs[i].shape[axis]\n",
    "        offsets.append(start)\n",
    "            \n",
    "    # The helper closure splits up the concatenated array back into the components of `arrs`\n",
    "    # and then runs `func1d` on them\n",
    "    def helperfunc(a, *args, **kwargs):\n",
    "        arrs = numpy.split(a, offsets)\n",
    "        return func1d(*[*arrs, *args], **kwargs)\n",
    "    \n",
    "    # Run `apply_along_axis` along the concatenated array\n",
    "    return numpy.apply_along_axis(helperfunc, axis, carrs, *args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,clim=get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['wnd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sst, ds_wnd = data['sst'],data['wnd']\n",
    "ds_wnd['wspd']=(ds_wnd.uwnd**2+ds_wnd.vwnd**2)**.5\n",
    "#interp doesn't work on chunked dims so rechunk\n",
    "ds_sst = ds_sst.chunk({'time':1,'lat':901,'lon':1800})\n",
    "ds_new = ds_sst.interp(lat = ds_wnd.lat,lon=ds_wnd.lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SST\n",
    "#remove mean, seasonal cycle, trend before analysis\n",
    "clim = ds_new.groupby('time.dayofyear').mean('time',keep_attrs=True,skipna=False)\n",
    "ds_new_tem = ds_new.groupby('time.dayofyear')-clim\n",
    "#detrending doesn't work with nan so fill with nan but will have to mask at end and pixels with nan in timeseries\n",
    "tem = ds_new_tem.fillna(0)\n",
    "ds_detrended_sst = signal.detrend(tem.analysed_sst,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_new_tem.analysed_sst.isel(lon=720,lat=310).plot()\n",
    "plt.plot(ds_new_tem.time,ds_detrended_sst[:,310,720])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WSPD\n",
    "#remove mean, seasonal cycle, trend before analysis\n",
    "clim = ds_wnd.groupby('time.dayofyear').mean('time',keep_attrs=True,skipna=False)\n",
    "ds_new_tem = ds_wnd.groupby('time.dayofyear')-clim\n",
    "#detrending doesn't work with nan so fill with nan but will have to mask at end and pixels with nan in timeseries\n",
    "tem = ds_new_tem.fillna(0)\n",
    "ds_detrended_wnd = signal.detrend(tem.wspd,axis=0)\n",
    "ds_new_tem.wspd.isel(lon=720,lat=310).plot()\n",
    "plt.plot(ds_new_tem.time,ds_detrended_wnd[:,310,720])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = multi_apply_along_axis(pearsonr, 0, [ds_detrended_sst,ds_detrended_wnd])\n",
    "print(corr.shape)\n",
    "print(type(corr))\n",
    "#not sure why by 1440 is blank\n",
    "acorr = corr[0,:,:]\n",
    "acorr2 = np.concatenate([acorr[:,720:1439],acorr[:,:1439],acorr[:,:720]],axis=1)\n",
    "#plt.imshow(acorr[:,:1439],vmin=-.1,vmax=.1,cmap='RdBu')\n",
    "#plt.imshow(acorr2,vmin=-.1,vmax=.1,cmap='viridis')\n",
    "data = acorr2\n",
    "data = np.nan_to_num(data,0)\n",
    "lowpass = ndimage.gaussian_filter(data, 40)\n",
    "gauss_highpass = data - lowpass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(lowpass,vmin=-.1,vmax=.1,cmap='RdBu')\n",
    "plt.imshow(gauss_highpass,vmin=-.1,vmax=.1,cmap='RdBu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

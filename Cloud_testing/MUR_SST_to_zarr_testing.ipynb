{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xarray: 0.12.1-C:\\Users\\gentemann\\Miniconda3\\envs\\satenv\\lib\\site-packages\\xarray\\__init__.py\n",
      "dask: 1.2.0-C:\\Users\\gentemann\\Miniconda3\\envs\\satenv\\lib\\site-packages\\dask\\__init__.py\n",
      "distributed: 1.27.1-C:\\Users\\gentemann\\Miniconda3\\envs\\satenv\\lib\\site-packages\\distributed\\__init__.py\n",
      "zarr: 2.3.1-C:\\Users\\gentemann\\Miniconda3\\envs\\satenv\\lib\\site-packages\\zarr\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import zarr\n",
    "import dask\n",
    "import distributed\n",
    "import os #needed to check that file exists\n",
    "from dask.distributed import Client, progress\n",
    "\n",
    "\n",
    "print('xarray: %s-%s' % (xr.__version__, xr.__file__))\n",
    "print('dask: %s-%s' % (dask.__version__, dask.__file__))\n",
    "print('distributed: %s-%s' % (distributed.__version__, distributed.__file__))\n",
    "print('zarr: %s-%s' % (zarr.__version__, zarr.__file__))\n",
    "\n",
    "#def get_sat_filename(date):\n",
    "#    dir_sat='F:/data/sst/jpl_mur/v4.1/'\n",
    "#    date = pd.to_datetime(date)\n",
    "#    syr, smon, sdym, sjdy = str(date.year), str(date.month).zfill(2), str(date.day).zfill(2), str(date.dayofyear).zfill(2)\n",
    "#    sat_filename =dir_sat + syr + '/'+ sjdy + '/' + syr + smon + sdym + '090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc'\n",
    "#    exists = os.path.isfile(sat_filename)\n",
    "#    return sat_filename, exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit: None\n",
      "python: 3.7.1 | packaged by conda-forge | (default, Mar 13 2019, 13:32:59) [MSC v.1900 64 bit (AMD64)]\n",
      "python-bits: 64\n",
      "OS: Windows\n",
      "OS-release: 10\n",
      "machine: AMD64\n",
      "processor: Intel64 Family 6 Model 63 Stepping 2, GenuineIntel\n",
      "byteorder: little\n",
      "LC_ALL: None\n",
      "LANG: None\n",
      "LOCALE: None.None\n",
      "libhdf5: 1.10.4\n",
      "libnetcdf: 4.6.2\n",
      "\n",
      "xarray: 0.12.1\n",
      "pandas: 0.24.2\n",
      "numpy: 1.16.3\n",
      "scipy: 1.2.1\n",
      "netCDF4: 1.5.1.1\n",
      "pydap: None\n",
      "h5netcdf: None\n",
      "h5py: 2.9.0\n",
      "Nio: None\n",
      "zarr: 2.3.1\n",
      "cftime: 1.0.3.4\n",
      "nc_time_axis: None\n",
      "PseudonetCDF: None\n",
      "rasterio: 1.0.22\n",
      "cfgrib: None\n",
      "iris: None\n",
      "bottleneck: 1.2.1\n",
      "dask: 1.2.0\n",
      "distributed: 1.27.1\n",
      "matplotlib: 3.0.3\n",
      "cartopy: 0.17.0\n",
      "seaborn: 0.9.0\n",
      "setuptools: 41.0.1\n",
      "pip: 19.1\n",
      "conda: None\n",
      "pytest: None\n",
      "IPython: 7.5.0\n",
      "sphinx: None\n"
     ]
    }
   ],
   "source": [
    "xr.show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:51060\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>16</li>\n",
       "  <li><b>Memory: </b>34.28 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:51060' processes=8 cores=16>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup Dask Cluster / Client\n",
    "client = Client(processes=True, n_workers=8)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creat a list of filenames, only necessary if you replicate the directory structure of the Ftp site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:/data/sst/jpl_mur/v4.1/2018\\\\100\\\\20180410090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read_date,end_date = np.datetime64('2018-04-10'),np.datetime64('2018-06-12')\n",
    "#read_date,end_date = np.datetime64('2002-06-01'),np.datetime64('2019-04-01')\n",
    "#filelist = []\n",
    "#while read_date<=(end_date+np.timedelta64(1,'D')):\n",
    "#    tem_filename,exists = get_sat_filename(read_date)\n",
    "#    if exists:\n",
    "#        filelist.append(tem_filename)\n",
    "#    read_date=read_date+np.timedelta64(1,'D')\n",
    "#print(filelist[0])\n",
    "from glob import glob\n",
    "filelist = glob('F:/data/sst/jpl_mur/v4.1/2018/*/*',recursive=True)\n",
    "filelist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open collection of netCDF files, concat along the ensemble dimension\n",
    "#ds = xr.open_mfdataset('/pool0/home/jhamman1/workdir/newman_ensemble/conus_ens_[01]*nc',\n",
    "#                       concat_dim=xr.Variable('ensemble', np.arange(100)),\n",
    "#                       chunks={'time': 366, 'lat': 224, 'lon': 464},\n",
    "#                       autoclose=True)\n",
    "ds = xr.open_mfdataset(filelist,coords='minimal', \n",
    "                       chunks={'time': 64, 'lat': 100, 'lon': 100})\n",
    "#17999, 36000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:           (lat: 17999, lon: 36000, time: 64)\n",
       "Coordinates:\n",
       "  * lat               (lat) float32 -89.99 -89.98 -89.97 ... 89.97 89.98 89.99\n",
       "  * lon               (lon) float32 -179.99 -179.98 -179.97 ... 179.99 180.0\n",
       "  * time              (time) datetime64[ns] 2018-04-10T09:00:00 ... 2018-06-12T09:00:00\n",
       "Data variables:\n",
       "    analysed_sst      (time, lat, lon) float32 dask.array<shape=(64, 17999, 36000), chunksize=(1, 100, 100)>\n",
       "    analysis_error    (time, lat, lon) float32 dask.array<shape=(64, 17999, 36000), chunksize=(1, 100, 100)>\n",
       "    mask              (time, lat, lon) float32 dask.array<shape=(64, 17999, 36000), chunksize=(1, 100, 100)>\n",
       "    sea_ice_fraction  (time, lat, lon) float32 dask.array<shape=(64, 17999, 36000), chunksize=(1, 100, 100)>\n",
       "    dt_1km_data       (time, lat, lon) timedelta64[ns] dask.array<shape=(64, 17999, 36000), chunksize=(1, 100, 100)>\n",
       "Attributes:\n",
       "    Conventions:                CF-1.5\n",
       "    title:                      Daily MUR SST, Final product\n",
       "    summary:                    A merged, multi-sensor L4 Foundation SST anal...\n",
       "    references:                 http://podaac.jpl.nasa.gov/Multi-scale_Ultra-...\n",
       "    institution:                Jet Propulsion Laboratory\n",
       "    history:                    created at nominal 4-day latency; replaced nr...\n",
       "    comment:                    MUR = \"Multi-scale Ultra-high Reolution\"\n",
       "    license:                    These data are available free of charge under...\n",
       "    id:                         MUR-JPL-L4-GLOB-v04.1\n",
       "    naming_authority:           org.ghrsst\n",
       "    product_version:            04.1\n",
       "    uuid:                       27665bc0-d5fc-11e1-9b23-0800200c9a66\n",
       "    gds_version_id:             2.0\n",
       "    netcdf_version_id:          4.1\n",
       "    date_created:               20180519T003623Z\n",
       "    start_time:                 20180410T090000Z\n",
       "    stop_time:                  20180410T090000Z\n",
       "    time_coverage_start:        20180409T210000Z\n",
       "    time_coverage_end:          20180410T210000Z\n",
       "    file_quality_level:         1\n",
       "    source:                     MODIS_T-JPL, MODIS_A-JPL, AMSR2-REMSS, AVHRR1...\n",
       "    platform:                   Terra, Aqua, GCOM-W, NOAA-19, MetOp-A, Buoys/...\n",
       "    sensor:                     MODIS, AMSR2, AVHRR, in-situ\n",
       "    Metadata_Conventions:       Unidata Observation Dataset v1.0\n",
       "    metadata_link:              http://podaac.jpl.nasa.gov/ws/metadata/datase...\n",
       "    keywords:                   Oceans > Ocean Temperature > Sea Surface Temp...\n",
       "    keywords_vocabulary:        NASA Global Change Master Directory (GCMD) Sc...\n",
       "    standard_name_vocabulary:   NetCDF Climate and Forecast (CF) Metadata Con...\n",
       "    southernmost_latitude:      -90.0\n",
       "    northernmost_latitude:      90.0\n",
       "    westernmost_longitude:      -180.0\n",
       "    easternmost_longitude:      180.0\n",
       "    spatial_resolution:         0.01 degrees\n",
       "    geospatial_lat_units:       degrees north\n",
       "    geospatial_lat_resolution:  0.01 degrees\n",
       "    geospatial_lon_units:       degrees east\n",
       "    geospatial_lon_resolution:  0.01 degrees\n",
       "    acknowledgment:             Please acknowledge the use of these data with...\n",
       "    creator_name:               JPL MUR SST project\n",
       "    creator_email:              ghrsst@podaac.jpl.nasa.gov\n",
       "    creator_url:                http://mur.jpl.nasa.gov\n",
       "    project:                    NASA Making Earth Science Data Records for Us...\n",
       "    publisher_name:             GHRSST Project Office\n",
       "    publisher_url:              http://www.ghrsst.org\n",
       "    publisher_email:            ghrsst-po@nceo.ac.uk\n",
       "    processing_level:           L4\n",
       "    cdm_data_type:              grid"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds['mask'] = ds['mask'].isel(ensemble=0, drop=True)\n",
    "#ds['elevation'] = ds['elevation'].isel(ensemble=0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for compression/encoding\n",
    "compressor = zarr.Blosc(cname='zstd', clevel=5, shuffle=zarr.Blosc.AUTOSHUFFLE)\n",
    "encoding = {v: {'compressor': compressor} for v in ds.data_vars}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://127.0.0.1:51717 remote=tcp://127.0.0.1:51060>\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 62% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 73% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "# wrtie the zarr dataset\n",
    "ds.to_zarr('F:/data/sst/jpl_mur/v4.1/MUR_Saildrone2018BajaCruise.zarr', mode='w', encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Worker process still alive after 4 seconds, killing\n",
      "distributed.nanny - WARNING - Worker process still alive after 4 seconds, killing\n",
      "distributed.nanny - WARNING - Worker process still alive after 4 seconds, killing\n",
      "distributed.nanny - WARNING - Worker process still alive after 4 seconds, killing\n",
      "distributed.nanny - WARNING - Worker process still alive after 4 seconds, killing\n",
      "distributed.nanny - WARNING - Worker process still alive after 4 seconds, killing\n",
      "distributed.nanny - WARNING - Worker process still alive after 4 seconds, killing\n",
      "distributed.nanny - WARNING - Worker process still alive after 4 seconds, killing\n",
      "distributed.nanny - WARNING - Worker process 48988 was killed by signal 15\n",
      "distributed.core - INFO - Event loop was unresponsive in Nanny for 39.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
      "distributed.core - INFO - Event loop was unresponsive in Nanny for 39.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
      "distributed.core - INFO - Event loop was unresponsive in Nanny for 39.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
      "distributed.core - INFO - Event loop was unresponsive in Nanny for 39.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
      "distributed.core - INFO - Event loop was unresponsive in Nanny for 39.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
      "distributed.core - INFO - Event loop was unresponsive in Nanny for 39.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
      "distributed.core - INFO - Event loop was unresponsive in Nanny for 39.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
      "distributed.core - INFO - Event loop was unresponsive in Nanny for 39.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
      "distributed.nanny - WARNING - Worker process 17456 was killed by signal 15\n",
      "distributed.nanny - WARNING - Worker process 48452 was killed by signal 15\n",
      "distributed.nanny - WARNING - Worker process 42764 was killed by signal 15\n"
     ]
    }
   ],
   "source": [
    "client.close()\n",
    "# Push things to google cloud storage\n",
    "# !gsutil -m cp -r /pool0/home/jhamman1/workdir/gmet.zarr gs://pangeo-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some testing and imaging of MUR SST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = ds.sel(lon=slice(-130,-114),lat=slice(20,40))\n",
    "subset.load()\n",
    "subset.analysed_sst.mean({'time'}).plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.analysed_sst.std({'time'}).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.analysed_sst.mean({'lat','lon'}).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.analysed_sst[0,:,:].plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data and create timeseries using PICES LME\n",
    "\n",
    "Look at SST, ocean currents, chl-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "#import numpy as np\n",
    "#from math import pi\n",
    "#import datetime as dt\n",
    "#import os\n",
    "#from os.path import exists\n",
    "import matplotlib.pyplot as plt\n",
    "#import cartopy.crs as ccrs\n",
    "#from datetime import *; from dateutil.relativedelta import *\n",
    "#from scipy.interpolate import make_interp_spline, BSpline\n",
    "#from scipy.signal import savgol_filter\n",
    "#import sys\n",
    "#import geopandas as gpd\n",
    "import cartopy.crs as ccrs\n",
    "#from cartopy.examples.arrows import sample_data\n",
    "#from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "#from matplotlib.figure import Figure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in PICES mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in mask file\n",
    "filename = './data/PICES_all_mask.nc'\n",
    "ds_pices = xr.open_dataset(filename)\n",
    "ds_pices.close()\n",
    "ds_pices.region_mask.plot(vmin=11,vmax=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_url = 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/ncdcOisst2Agg'\n",
    "ds = xr.open_dataset(aggr_url).isel(altitude=0).drop({'anom','err','ice'})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_climatology = ds.groupby('time.month').mean('time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_anomalies = sst_climatology.groupby('time.month') - climatology\n",
    "sst_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/pmlEsaCCI31OceanColorDaily'\n",
    "aggr_url = 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/pmlEsaCCI31OceanColorMonthly'\n",
    "ds = xr.open_dataset(aggr_url)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.chlor_a.sel(latitude=slice(90,20))\n",
    "ds\n",
    "#chl_climatology = ds.chlor_a.groupby('time.month').mean('time')\n",
    "#chl_anomalies = ds.chlor_a.groupby('time.month') - climatology\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_url = 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdlasFnWind10'\n",
    "ds = xr.open_dataset(aggr_url)\n",
    "wnd_climatology = ds.groupby('time.month').mean('time')\n",
    "wnd_anomalies = sst_climatology.groupby('time.month') - climatology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_url = 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplOscar_LonPM180'\n",
    "ds = xr.open_dataset(aggr_url)\n",
    "cur_climatology = ds.groupby('time.month').mean('time')\n",
    "cur_anomalies = sst_climatology.groupby('time.month') - climatology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data_oscar = 'F:/data/sat_data/oscar/L4/oscar_third_deg/'\n",
    "dir_data_sss='F:/data/model_data/CMEM/global-reanalysis-phy-001-030-monthly/'\n",
    "dir_data_sst = 'F:/data/sst/cmc/CMC0.2deg/v2/monthly/' \n",
    "dir_data_ccmp='F:/data/sat_data/ccmp/v02.0/'\n",
    "dir_data_mld='F:/data/model_data/godas/'\n",
    "dir_figs = 'F:/data/NASA_biophysical/pices/figures/'\n",
    "dir_timeseries = 'F:/data/NASA_biophysical/timeseries_data/'\n",
    "dir_shp = 'F:/data/NASA_biophysical/pices/shapefiles/'\n",
    "#oscar - reran all monthly fies & climatology, updated through 2018, 2/1/2019\n",
    "#ccmp - added RVort, from 6-hourly creating new monthly and climatology 4/2/2019 \n",
    "#sst - updated all files, reprocessed monthly, climatology 2/1/2019\n",
    "#sss - rerunning 2018, cal climatology 2/2/2019\n",
    "#ssh - re running 2018 , cal climatology 2/2/2019\n",
    "#mld - reran climatology, downloaded final 2018 file 2/1/2019\n",
    "\n",
    "def weighted_mean_of_subset(ds,data_in,data_in2,cond):\n",
    "    #ds = input xarray data to have weighted mean\n",
    "    #data_in = ds.data some data variable that has a nan mask applied where no data lat,lon dims\n",
    "    #subset condition\n",
    "    R = 6.37e6 #radius of earth in m\n",
    "    # we know already that the spacing of the points is 1/4 degree latitude\n",
    "    grid_dy,grid_dx = (ds.lat[0]-ds.lat[1]).data,(ds.lon[0]-ds.lon[1]).data\n",
    "    dϕ = np.deg2rad(grid_dy)\n",
    "    dλ = np.deg2rad(grid_dx)\n",
    "    dA = R**2 * dϕ * dλ * np.cos(np.deg2rad(ds.lat)) #dA.plot()\n",
    "    pixel_area = dA.where(cond)  #pixel_area.plot()\n",
    "    pixel_area = pixel_area.where(np.isfinite(data_in) & np.isfinite(data_in2))\n",
    "    total_ocean_area = pixel_area.sum(dim=('lon', 'lat'))\n",
    "    data_weighted_mean = (ds * pixel_area).sum(dim=('lon', 'lat')) / total_ocean_area\n",
    "    return data_weighted_mean\n",
    "\n",
    "\n",
    "def get_climatology_filename(data_type):\n",
    "    if data_type=='oscar':\n",
    "        filename = dir_data_oscar + 'climatology_2000_2018_monthly_data_oscar.nc'        \n",
    "    if data_type=='sss' or data_type=='ssh':\n",
    "        filename = dir_data_sss + 'clim/climatology_1993_2017_mercatorglorys12v1_gl12_mean.nc'\n",
    "    if data_type=='sst':\n",
    "        filename = dir_data_sst + 'monthly_climatology_1992_2017_120000-CMC-L4_GHRSST-SSTfnd-CMC0.2deg-GLOB-v02.0-fv02.0.nc'\n",
    "    if data_type == 'ccmp':\n",
    "        filename = dir_data_ccmp + 'monthly/climatology_1988_2018_CCMP_Wind_Analysis_L3.0.nc'\n",
    "    if data_type == 'mld':\n",
    "        filename = dir_data_mld + 'monthly_climatology_dbss_obml_1992_2018.nc'\n",
    "    return filename\n",
    "\n",
    "def get_data_filename(data_type,lyr):\n",
    "    if data_type == 'oscar':\n",
    "        filename = dir_data_oscar + str(lyr) + 'monthly_data_oscar.nc'\n",
    "    if data_type=='sss' or data_type=='ssh':\n",
    "        filename = dir_data_sss + str(lyr) + '/'+ 'year_subset_mercatorglorys12v1_gl12_mean_' + str(lyr) + '.nc'\n",
    "        if lyr==2018:\n",
    "            filename = 'F:/data/model_data/CMEM/global-analysis-forecast-phys_001_015/monthly/year_subset_metoffice_coupled_orca025_GL4_SAL_b2018_dm20180208.nc'\n",
    "    if data_type=='sst':\n",
    "        filename = dir_data_sst + str(lyr) + 'monthly_average_' + '120000-CMC-L4_GHRSST-SSTfnd-CMC0.2deg-GLOB-v02.0-fv02.0.nc'\n",
    "    if data_type == 'ccmp':\n",
    "        filename = dir_data_ccmp + 'monthly/CCMP_Wind_Analysis_' + str(lyr) + '_V02.0_L3.0_RSS.nc'\n",
    "    if data_type == 'mld':\n",
    "        filename = dir_data_mld + 'dbss_obml.' + str(lyr) + '.nc'\n",
    "    return filename\n",
    "\n",
    "def get_monthly_oscar(lyr,iclim):\n",
    "    if iclim==0:\n",
    "        filename = get_data_filename('oscar',lyr)\n",
    "    else:\n",
    "        filename = get_climatology_filename('oscar')\n",
    "    print(filename)\n",
    "    ds=xr.open_dataset(filename)\n",
    "    ds = ds.sel(lon=slice(20.0,379.9))\n",
    "    ds = ds.assign_coords(lon=(((ds.lon + 180) % 360) - 180)).sortby('lon').sortby('lat')\n",
    "#    ds = ds.rename({'spd': 'data'})\n",
    "#    ds = ds.mean('depth')  #get rid of depth in index\n",
    "    ds['spd']=(ds.u**2+ds.v**2)**.5\n",
    "    ds['dir']=np.arctan2(ds.v,ds.u)* 180./pi\n",
    "  #  ds=ds.drop('year')\n",
    "    ds.close()\n",
    "    return ds\n",
    "\n",
    "def get_monthly_mld(lyr,iclim):\n",
    "    if iclim==0:\n",
    "        filename = get_data_filename('mld',lyr)\n",
    "    else:\n",
    "        filename = get_climatology_filename('mld')\n",
    "    print(filename)\n",
    "    ds=xr.open_dataset(filename)\n",
    "    ds = ds.assign_coords(lon=(((ds.lon + 180) % 360) - 180)).sortby('lon').sortby('lat')\n",
    " #   ds = ds.rename({'dbss_obml': 'data'})\n",
    "    ds.close()\n",
    "    return ds\n",
    "\n",
    "def get_monthly_ccmp(lyr,iclim):\n",
    "    if iclim==0:\n",
    "        filename = get_data_filename('ccmp',lyr)\n",
    "    else:\n",
    "        filename = get_climatology_filename('ccmp')\n",
    "    print(filename)\n",
    "    ds=xr.open_dataset(filename)\n",
    "    ds = ds.assign_coords(lon=(((ds.lon + 180) % 360) - 180)).sortby('lon').sortby('lat')\n",
    "    ds['spd']=(ds.uwnd**2+ds.vwnd**2)**.5\n",
    "    ds['dir']=np.arctan2(ds.vwnd,ds.uwnd)* 180./pi    \n",
    "#    ds = ds.rename({'spd': 'data'})\n",
    "    ds.close()\n",
    "    return ds\n",
    "\n",
    "def get_monthly_sst(lyr,iclim):\n",
    "    if iclim==0:\n",
    "        filename = get_data_filename('sst',lyr)\n",
    "    else:\n",
    "        filename = get_climatology_filename('sst')\n",
    "    print(filename)\n",
    "    ds=xr.open_dataset(filename)\n",
    " #   ds = ds.rename({'analysed_sst': 'data'})\n",
    "    ds.close()\n",
    "    return ds\n",
    "\n",
    "def get_monthly_sss(lyr,iclim):\n",
    "    if iclim==0:\n",
    "        filename = get_data_filename('sss',lyr)\n",
    "    else:\n",
    "        filename = get_climatology_filename('sss')\n",
    "    if lyr<2018:\n",
    "        ds=xr.open_dataset(filename,drop_variables=['mlotst','bottomT','sithick','siconc','usi','vsi','thetao','uo','vo','zos'])\n",
    "    else:\n",
    "        ds=xr.open_dataset(filename,drop_variables=['zos'])\n",
    "    print(filename)\n",
    "#    ds = ds.rename({'so': 'data'})\n",
    "    ds.close()\n",
    "    return ds\n",
    "\n",
    "def get_monthly_ssh(lyr,iclim):\n",
    "    if iclim==0:\n",
    "        filename = get_data_filename('sss',lyr)  #same file as sss\n",
    "    else:\n",
    "        filename = get_climatology_filename('sss') #same file as sss\n",
    "    print(filename)\n",
    "    if lyr<2018:\n",
    "        ds=xr.open_dataset(filename,drop_variables=['mlotst','bottomT','sithick','siconc','usi','vsi','thetao','uo','vo','so'])\n",
    "    else:\n",
    "        ds=xr.open_dataset(filename,drop_variables=['so'])\n",
    "   # ds = ds.rename({'zos': 'data'})\n",
    "    ds.close()\n",
    "    return ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darray = ['oscar','mld','ccmp','sst','sss','ssh']\n",
    "dir_shp = './data/'\n",
    "data_dir = './data/'\n",
    "data_fig = './figures/'\n",
    "\n",
    "#read in mask file\n",
    "filename = './data/PICES_all_mask.nc'\n",
    "ds_pices = xr.open_dataset(filename)\n",
    "ds_pices.close()\n",
    "\n",
    "#region = np.arange(0,21)\n",
    "for itype in range(0,6):\n",
    "    init_data = 0\n",
    "    dtype = darray[itype]\n",
    "    for lyr in range(1993,2019):\n",
    "        iclim = 0\n",
    "        if itype == 0:\n",
    "            ds = get_monthly_oscar(lyr,0)\n",
    "            ds = ds.drop({'spd','dir'})\n",
    "            ds2 = get_monthly_oscar(lyr,1)\n",
    "            ds2=xr.Dataset(data_vars={'v': (('time','lat','lon'),ds2.v),\n",
    "                                      'u': (('time','lat','lon'),ds2.u)},\n",
    "                            coords={'lat':ds2.lat,'lon':ds2.lon,'time':ds.time})\n",
    "            data_in = ds.u#[0,:,:]\n",
    "            data_in2 = ds2.u#[0,:,:]\n",
    "        if itype == 1:\n",
    "            ds = get_monthly_mld(lyr,0)\n",
    "            ds2 = get_monthly_mld(lyr,1)\n",
    "            ds2=xr.Dataset(data_vars={'dbss_obml': (('time','lat','lon'),ds2.dbss_obml),},\n",
    "                            coords={'lat':ds2.lat,'lon':ds2.lon,'time':ds.time})\n",
    "            data_in = ds.dbss_obml#[0,:,:]\n",
    "            data_in2 = ds2.dbss_obml#[0,:,:]\n",
    "        if itype == 2:\n",
    "            ds = get_monthly_ccmp(lyr,0)\n",
    "            ds = ds.drop({'spd','dir'})\n",
    "            ds2 = get_monthly_ccmp(lyr,1)\n",
    "            ds2=xr.Dataset(data_vars={'vwnd': (('time','lat','lon'),ds2.vwnd),\n",
    "                                      'uwnd': (('time','lat','lon'),ds2.uwnd),\n",
    "                                      'rel_vorticity': (('time','lat','lon'),ds2.rel_vorticity)},\n",
    "                            coords={'lat':ds2.lat,'lon':ds2.lon,'time':ds.time})\n",
    "            data_in = ds.uwnd#[0,:,:]\n",
    "            data_in2 = ds2.uwnd#[0,:,:]\n",
    "        if itype == 3:\n",
    "            ds = get_monthly_sst(lyr,0)\n",
    "            ds2 = get_monthly_sst(lyr,1)\n",
    "            ds2=xr.Dataset(data_vars={'analysed_sst': (('time','lat','lon'),ds2.analysed_sst),},\n",
    "                            coords={'lat':ds2.lat,'lon':ds2.lon,'time':ds.time})\n",
    "            data_in = ds.analysed_sst#[0,:,:]\n",
    "            data_in2 = ds2.analysed_sst#[0,:,:]\n",
    "        if itype == 4:\n",
    "            ds = get_monthly_sss(lyr,0)\n",
    "            ds2 = get_monthly_sss(lyr,1)\n",
    "            ds2=ds2.drop('depth') #0.49m\n",
    "            ds2=xr.Dataset(data_vars={'so': (('time','lat','lon'),ds2.so),},\n",
    "                            coords={'lat':ds2.lat,'lon':ds2.lon,'time':ds.time})\n",
    "            data_in = ds.so#[0,:,:]\n",
    "            data_in2 = ds2.so#[0,:,:]\n",
    "        if itype == 5:\n",
    "            ds = get_monthly_ssh(lyr,0)\n",
    "            ds2 = get_monthly_ssh(lyr,1)\n",
    "            ds2=ds2.drop('depth') #0.49m\n",
    "            ds2=xr.Dataset(data_vars={'zos': (('time','lat','lon'),ds2.zos),},\n",
    "                            coords={'lat':ds2.lat,'lon':ds2.lon,'time':ds.time})\n",
    "            data_in = ds.zos#[0,:,:]\n",
    "            data_in2 = ds2.zos#[0,:,:]\n",
    "#now iterate over regions\n",
    "        init_data2 = 0\n",
    "        coord_region=[]\n",
    "        for iregion in range(11,25):\n",
    "            mask_interp = ds_pices.interp_like(ds,method='nearest')\n",
    "            cond = (mask_interp.region_mask==iregion)\n",
    "            ds_mean = weighted_mean_of_subset(ds,data_in,data_in2,cond)\n",
    "            ds_mean_clim = weighted_mean_of_subset(ds2,data_in,data_in2,cond)\n",
    "            ds_anom = ds_mean - ds_mean_clim\n",
    "            if itype == 0:  #if currents or winds need to recal spd dir from means of u and v\n",
    "                ds_mean['spd']=(ds_mean.u**2+ds_mean.v**2)**.5\n",
    "                ds_mean['dir']=np.arctan2(ds_mean.v,ds_mean.u)* 180./pi                \n",
    "                ds_anom['spd']=(ds_anom.u**2+ds_anom.v**2)**.5\n",
    "                ds_anom['dir']=np.arctan2(ds_anom.v,ds_anom.u)* 180./pi                \n",
    "                ds_mean_clim['spd']=(ds_mean_clim.u**2+ds_mean_clim.v**2)**.5\n",
    "                ds_mean_clim['dir']=np.arctan2(ds_mean_clim.v,ds_mean_clim.u)* 180./pi                \n",
    "            if itype==2:  #if currents or winds need to recal spd dir from means of u and v\n",
    "                ds_mean['spd']=(ds_mean.uwnd**2+ds_mean.vwnd**2)**.5\n",
    "                ds_mean['dir']=np.arctan2(ds_mean.vwnd,ds_mean.uwnd)* 180./pi                \n",
    "                ds_anom['spd']=(ds_anom.uwnd**2+ds_anom.vwnd**2)**.5\n",
    "                ds_anom['dir']=np.arctan2(ds_anom.vwnd,ds_anom.uwnd)* 180./pi                \n",
    "                ds_mean_clim['spd']=(ds_mean_clim.uwnd**2+ds_mean_clim.vwnd**2)**.5\n",
    "                ds_mean_clim['dir']=np.arctan2(ds_mean_clim.vwnd,ds_mean_clim.uwnd)* 180./pi                \n",
    "            if init_data2==0:\n",
    "                ds_box = ds_mean\n",
    "                ds_box_clim = ds_mean_clim\n",
    "                ds_box_anom = ds_anom\n",
    "                coord_region.append(iregion)\n",
    "                init_data2=1\n",
    "            else:\n",
    "                ds_box = xr.concat([ds_box,ds_mean],dim='region')\n",
    "                ds_box_clim = xr.concat([ds_box_clim,ds_mean_clim],dim='region')\n",
    "                ds_box_anom = xr.concat([ds_box_anom,ds_anom],dim='region')\n",
    "                coord_region.append(iregion)\n",
    "        if init_data==0:\n",
    "            ds_newbox = ds_box\n",
    "            ds_newbox_clim = ds_box_clim\n",
    "            ds_newbox_anom = ds_box_anom\n",
    "            init_data=1\n",
    "        else:\n",
    "            ds_newbox = xr.concat([ds_newbox,ds_box],dim='time')\n",
    "            ds_newbox_clim = xr.concat([ds_newbox_clim,ds_box_clim],dim='time')\n",
    "            ds_newbox_anom = xr.concat([ds_newbox_anom,ds_box_anom],dim='time')\n",
    "        #print(ds_newbox.box)\n",
    "    ds_newbox.coords['region']=coord_region\n",
    "    ds_newbox_clim.coords['region']=coord_region\n",
    "    ds_newbox_anom.coords['region']=coord_region\n",
    "    print(ds_newbox)\n",
    "    \n",
    "    filename_out = dir_timeseries + dtype + '_pices_data_v2.nc'\n",
    "    ds_newbox.to_netcdf(filename_out)\n",
    "      filename_out_clim = dir_timeseries + dtype + '_pices_data_minus_clim_v2.nc'\n",
    "    ds_newbox_anom.to_netcdf(filename_out_clim)\n",
    "    df = ds_newbox_anom.to_dataframe()\n",
    "    filename_out = dir_timeseries + dtype + '_pices_data_minus_clim_v2.csv'\n",
    "    df.to_csv(filename_out)\n",
    "    filename_out_clim = dir_timeseries + dtype + '_pices_data_clim_v2.nc'\n",
    "    ds_newbox_clim.to_netcdf(filename_out_clim)\n",
    "    df = ds_newbox_clim.to_dataframe()\n",
    "    filename_out = dir_timeseries + dtype + '_pices_data_clim_v2.csv'\n",
    "    df.to_csv(filename_out)\n",
    "        \n",
    "    print('out!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old testing code\n",
    "this was used to fine tune the masking using in the weighted mean calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyr=2005\n",
    "ds = get_monthly_sst(lyr,0)\n",
    "ds2 = get_monthly_sst(lyr,1)\n",
    "ds2=xr.Dataset(data_vars={'analysed_sst': (('time','lat','lon'),ds2.analysed_sst),},\n",
    "                coords={'lat':ds2.lat,'lon':ds2.lon,'time':ds.time})\n",
    "data_in = ds.analysed_sst#[0,:,:]\n",
    "data_in2 = ds2.analysed_sst#[0,:,:]\n",
    "mask_interp = ds_pices.interp_like(ds,method='nearest')\n",
    "iregion = 14\n",
    "cond = (mask_interp.region_mask==iregion)\n",
    "ds_mean = weighted_mean_of_subset(ds,data_in,data_in2,cond)\n",
    "ds_mean_clim = weighted_mean_of_subset(ds2,data_in,data_in2,cond)\n",
    "print(ds_mean.analysed_sst.data-273.15)\n",
    "print(ds_mean_clim.analysed_sst.data-273.15)\n",
    "\n",
    "\n",
    "R = 6.37e6 #radius of earth in m\n",
    "# we know already that the spacing of the points is 1/4 degree latitude\n",
    "grid_dy,grid_dx = (ds.lat[0]-ds.lat[1]).data,(ds.lon[0]-ds.lon[1]).data\n",
    "dϕ = np.deg2rad(grid_dy)\n",
    "dλ = np.deg2rad(grid_dx)\n",
    "dA = R**2 * dϕ * dλ * np.cos(np.deg2rad(ds.lat)) #dA.plot()\n",
    "pixel_area = dA.where(cond)/1000000  #pixel_area.plot()  PUT into km2\n",
    "pixel_area = pixel_area.where(np.isfinite(data_in) & np.isfinite(data_in2))\n",
    "total_ocean_area = pixel_area.sum(dim=('lon', 'lat'))\n",
    "data_weighted_mean = (ds2 * pixel_area).sum(dim=('lon', 'lat')) / total_ocean_area\n",
    "print(data_weighted_mean.analysed_sst.data-273.15)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

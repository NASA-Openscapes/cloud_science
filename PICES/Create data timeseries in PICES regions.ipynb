{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data and create timeseries using PICES LME\n",
    "\n",
    "Look at SST, ocean currents, chl-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "global ds_pices360\n",
    "sys.path.append('./subroutines/')\n",
    "import pices\n",
    "\n",
    "adir_data = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in PICES mask\n",
    "\n",
    "- Each dataset finds a unique and different way to define lat / lon or order them.\n",
    "- There is a need for standardization in this area\n",
    "- The basic PICES mask is -180 to 180 lon and -90 to 90 lat\n",
    "- Below different maps are created for 0 to 360 lon\n",
    "- Then each of the two different lon maps are also copied to reverse lat, 90 to -90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pices360 = pices.get_pices_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pices360.sel(lon=slice(115,250),lat=slice(20,70)).region_mask.plot(vmin=11,vmax=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pices360.region_mask.plot.hist(bins=np.arange(10.5,27))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# don't run this\n",
    "- create local files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds.to_netcdf(file)\n",
    "file = pices.get_filename('sst')\n",
    "ds=xr.open_dataset(file)\n",
    "ds.close()\n",
    "#ds=ds.sortby(ds.lat,ascending=True)\n",
    "#ds = ds.drop('time_bnds')\n",
    "#ds.to_netcdf(file)\n",
    "ds_sst = ds\n",
    "\n",
    "#wind\n",
    "file = pices.get_filename('wind')\n",
    "aggr_url = 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdlasFnWind10'\n",
    "ds = xr.open_dataset(aggr_url).rename({'latitude':'lat','longitude':'lon'}).drop({'taux_mean','tauy_mean','curl'})\n",
    "ds.to_netcdf(file)\n",
    "\n",
    "#currents\n",
    "aggr_url = 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplOscar'\n",
    "ds = xr.open_dataset(aggr_url).isel(depth=0).rename({'latitude':'lat','longitude':'lon'}).drop({'um','vm'})\n",
    "#date1 = pd.Series(pd.date_range('2019-09-01', periods=3*24, freq='H'))\n",
    "date1 = pd.Series(pd.period_range('1992-10-01', periods=27*12, freq='M'))\n",
    "init=0\n",
    "for d in date1:\n",
    "    dstr=str(d.year)+'-'+str(d.month).zfill(2)\n",
    "    dstr2=str(d.year)+'-'+str(d.month).zfill(2)+'-01'\n",
    "    ds2=ds.sel(time=slice(dstr,dstr)).sel(lon=slice(20.0,379.9))\n",
    "    ds2 = ds2.assign_coords(lon=(((ds2.lon + 180) % 360) - 180)).sortby('lon').sortby('lat',ascending=True)\n",
    "    ds3 = ds2.interp(lat=ds_sst.lat,lon=ds_sst.lon,method='linear').mean('time',keep_attrs=True)\n",
    "    ds3=ds3.assign_coords(time=np.datetime64(dstr2))\n",
    "    if init==0:\n",
    "        ts=ds3\n",
    "        init=init+1\n",
    "    else:\n",
    "        ts=xr.concat((ts,ds3),dim='time')\n",
    "        #break\n",
    "ts.to_netcdf('cur_mean.nc')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in SST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn,clim,anom = pices.get_pices_data('sst',13,'1992-01-01','2019-08-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anom.sst.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pices.get_filename('sst')\n",
    "\n",
    "ds = xr.open_dataset(file)\n",
    "print('lat range',ds.lat[0].data,ds.lat[-1].data)\n",
    "print('lon range',ds.lon[0].data,ds.lon[-1].data)\n",
    "\n",
    "#interpolate mask\n",
    "mask_interp = ds_pices360_revlat.interp_like(ds,method='nearest')\n",
    "\n",
    "\n",
    "#create sst mean for pices region\n",
    "for iregion in range(11,25):\n",
    "    cond = (mask_interp.region_mask==iregion)\n",
    "    tem = weighted_mean_of_data(ds.sst,cond)\n",
    "    tem=tem.assign_coords(region=iregion)\n",
    "    if iregion==11:\n",
    "        sst_mean=tem\n",
    "    else:\n",
    "        sst_mean = xr.concat([sst_mean, tem], dim='region')\n",
    "\n",
    "#make climatology and anomalies using .groupby method\n",
    "sst_climatology = sst_mean.groupby('time.month').mean('time')\n",
    "sst_anomalies = sst_mean.groupby('time.month') - sst_climatology\n",
    "\n",
    "sst_mean.to_netcdf(adir_data+'sst_mean.nc')\n",
    "sst_climatology.to_netcdf(adir_data+'sst_climatology.nc')\n",
    "sst_anomalies.to_netcdf(adir_data+'sst_anomalies.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in wind data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_url = 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdlasFnWind10'\n",
    "ds = xr.open_dataset(aggr_url).rename({'latitude':'lat','longitude':'lon'}).drop({'taux_mean','tauy_mean','curl'})\n",
    "print('lat range',ds.lat[0].data,ds.lat[-1].data)\n",
    "print('lon range',ds.lon[0].data,ds.lon[-1].data)\n",
    "\n",
    "#interpolate mask\n",
    "mask_interp = ds_pices360.interp_like(ds,method='nearest')\n",
    "\n",
    "for iregion in range(11,25):\n",
    "    cond = (mask_interp.region_mask==iregion)\n",
    "    tem = weighted_mean_of_data(ds,cond)\n",
    "    tem=tem.assign_coords(region=iregion)\n",
    "    if iregion==11:\n",
    "        wnd_mean=tem\n",
    "    else:\n",
    "        wnd_mean = xr.concat([wnd_mean, tem], dim='region')\n",
    "\n",
    "#make climatology and anomalies using .groupby method\n",
    "wnd_climatology = wnd_mean.groupby('time.month').mean('time')\n",
    "wnd_anomalies = wnd_mean.groupby('time.month') - wnd_climatology\n",
    "\n",
    "wnd_mean.to_netcdf(adir_data+'wnd_mean.nc')\n",
    "wnd_climatology.to_netcdf(adir_data+'wnd_climatology.nc')\n",
    "wnd_anomalies.to_netcdf(adir_data+'wnd_anomalies.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Ocean current data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_url = 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplOscar'\n",
    "ds = xr.open_dataset(aggr_url).isel(depth=0).rename({'latitude':'lat','longitude':'lon'}).drop({'um','vm'})\n",
    "print('lat range',ds.lat[0].data,ds.lat[-1].data)\n",
    "print('lon range',ds.lon[0].data,ds.lon[-1].data)\n",
    "\n",
    "#subset\n",
    "ds = ds.sel(lon=slice(115,250),lat=slice(70,20))\n",
    "\n",
    "#interpolate mask\n",
    "mask_interp = ds_pices360_revlat.interp_like(ds,method='nearest')\n",
    "\n",
    "for iregion in range(11,25):\n",
    "    cond = (mask_interp.region_mask==iregion)\n",
    "    tem = weighted_mean_of_data(ds,cond)\n",
    "    tem=tem.assign_coords(region=iregion)\n",
    "    if iregion==11:\n",
    "        cur_mean=tem\n",
    "    else:\n",
    "        cur_mean = xr.concat([cur_mean, tem], dim='region')\n",
    "\n",
    "#make climatology and anomalies using .groupby method\n",
    "cur_climatology = cur_mean.groupby('time.month').mean('time')\n",
    "cur_anomalies = cur_mean.groupby('time.month') - cur_climatology\n",
    "\n",
    "cur_mean.to_netcdf(adir_data+'cur_mean.nc')\n",
    "cur_climatology.to_netcdf(adir_data+'cur_climatology.nc')\n",
    "cur_anomalies.to_netcdf(adir_data+'cur_anomalies.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in chl-a data\n",
    "\n",
    "- The chl-a data is on a 4km grid, too high resolution to deal unless running on the cloud.\n",
    "- For now, it is subsetted and interpolated onto a 1 deg grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_url = 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/pmlEsaCCI31OceanColorMonthly'\n",
    "ds = xr.open_dataset(aggr_url).rename({'latitude':'lat','longitude':'lon'})\n",
    "print('lat range',ds.lat[0].data,ds.lat[-1].data)\n",
    "print('lon range',ds.lon[0].data,ds.lon[-1].data)\n",
    "\n",
    "#subset\n",
    "#ds = ds.sel(lon=slice(115,250),lat=slice(70,20))\n",
    "dsA = ds.chlor_a.sel(lon=slice(-180,-110),lat=slice(70,20))\n",
    "dsB = ds.chlor_a.sel(lon=slice(115,180),lat=slice(70,20))\n",
    "\n",
    "\n",
    "m=[]\n",
    "for imon in range(0,250,5):\n",
    "    ds2 = dsA.isel(time=slice(imon,imon+5))\n",
    "    ds3 = ds2.interp(lat=np.arange(20,70),lon=np.arange(-180,-110))\n",
    "    if imon==0:\n",
    "        m=ds3\n",
    "    else:\n",
    "        m = xr.concat([m,ds3],dim='time')\n",
    "dsA = m  \n",
    "\n",
    "m=[]\n",
    "for imon in range(0,250,5):\n",
    "    ds2 = dsB.isel(time=slice(imon,imon+5))\n",
    "    ds3 = ds2.interp(lat=np.arange(20,70),lon=np.arange(115,180))\n",
    "    if imon==0:\n",
    "        m=ds3\n",
    "    else:\n",
    "        m = xr.concat([m,ds3],dim='time')\n",
    "dsB = m  \n",
    "ds = xr.concat([dsA,dsB],dim='lon')\n",
    "ds.coords['lon'] = np.mod(ds['lon'], 360)\n",
    "ds = ds.sortby(ds.lon)\n",
    "#create  mean for pices region\n",
    "iregion=13\n",
    "mask_interp = ds_pices360.interp_like(ds,method='nearest')\n",
    "cond = (mask_interp.region_mask==iregion)\n",
    "chl_mean = weighted_mean_of_data(ds,cond)\n",
    "\n",
    "#make climatology and anomalies using .groupby method\n",
    "chl_climatology = chl_mean.groupby('time.month').mean('time')\n",
    "chl_anomalies = chl_mean.groupby('time.month') - chl_climatology\n",
    "\n",
    "chl_mean.to_netcdf(adir_data+'chl_mean.nc')\n",
    "chl_climatology.to_netcdf(adir_data+'chl_climatology.nc')\n",
    "chl_anomalies.to_netcdf(adir_data+'chl_anomalies.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing still"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
